---
date: 2025-10-23 16:43:22
tags: dailynote
rating: ⭐
excerpt: 
---

## TODO

- [ ] 学习lora后，回去看adapt综述论文和b站的两个视频[大模型时代下做科研的四个思路【论文精读·52】_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1oX4y1d7X6?spm_id_from=333.788.videopod.sections&vd_source=ca057beeef58161f396ba6bc8f855c34) [多模态经典论文讲解 4：VLMO_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1MAK3zkEhT?spm_id_from=333.788.videopod.sections&vd_source=ca057beeef58161f396ba6bc8f855c34&p=4)
- [ ] zotero里面放了几篇论文，待看，比如今年联邦大模型论文等。Federated intelligence: When large AI models meet federated fine-tuning and collaborative reasoning at the network edge/  FedDAT
- [ ] 了解一下[https://huggingface.co/docs/peft/index]前几年PEFT很火
- [ ] 再看一下后两个方法。 [大模型时代下做科研的四个思路【论文精读·52】_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1oX4y1d7X6?spm_id_from=333.788.videopod.sections&vd_source=ca057beeef58161f396ba6bc8f855c34)
## Tracking

联邦大模型是主流创新（结合lora）
lora是adapt的一个实现方式。
今年最火的是视频生成，能结合吗？

数据增强一般是数据不够的情况下才会使用的，然而：
多模态的预训练中，数据很多，不需要数据增强了。但是相反，在多模态下游任务里，在做transfer的时候，因为多模态的下游任务的数据集不多。可以考虑在finetunig的时候使用数据增强??明天再看一下[大模型时代下做科研的四个思路【论文精读·52】_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1oX4y1d7X6?spm_id_from=333.788.videopod.sections&vd_source=ca057beeef58161f396ba6bc8f855c34)

可能的idea：你了解BLIP的caption filter吗？它可以用于non-iid数据吗？ 
	它的目的是生成更好的数据，并且是一个插件，不是blip的组成部分，可以训练别的模型