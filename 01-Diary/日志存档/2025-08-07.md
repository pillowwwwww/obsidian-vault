---
date: 2025-08-07 16:30:46
tags: dailynote
rating: ⭐
excerpt: 
---

## TODO

- [ ] 任何事情都能在五小时之内做完！
- [ ] 多喝水，避免久坐不动
- [ ] 阅读一篇文献

## Tracking

### 1. 误解澄清：准确率0.6 不是“单张图像的随机概率”

- 准确率0.6 的真实含义：

- 这是模型在整个测试集（e.g., CIFAR-10的10,000张不同图像）上的平均表现：模型正确分类了约60%的图像（e.g., 6000张正确，4000张错）。

- 它不是针对单张图像的“概率”。例如，对一张特定猫的照片，模型可能总是预测正确（100%），对另一张狗的照片总是预测错误（0%），平均下来是0.6。

- 比喻：想象一个医生诊断100个病人，准确率0.6 意味着他诊断对了60个病人。但对同一个病人检查100次，他不会“随机对60次”——每次都会给出相同诊断（因为病人症状固定）。如果诊断变了，那是因为加了“随机因素”（e.g., 医生心情或测量误差），但默认没有。

- 为什么不“随机60次正确”：

- 模型不是“随机抽样”的（如抛硬币）。它是一个确定性函数：输入固定（同一张图像 + 相同变换），模型参数固定（从 "best_model.pth" 加载），输出就固定（每次相同的 output 和 argmax）。

- PyTorch模型在 eval() 模式下无随机（no dropout, no random ops），所以运行100次输出相同，就像Java中调用 int add(int a, int b) { return a + b; } 100次，add(1,2) 总是3。

- 如果模型有随机组件（e.g., dropout 在 train 模式），输出可能变，但你的代码用 model.eval() 和 no_grad()，刻意禁用随机，确保稳定预测。