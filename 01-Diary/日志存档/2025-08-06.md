---
date: 2025-08-06 16:46:08
tags: dailynote
rating: ⭐
excerpt: 
---

## TODO

- [ ] 任何事情都能在五小时之内做完！
- [ ] 多喝水，避免久坐不动
- [ ] 阅读一篇文献

## Tracking

### idea
微调：pfl的每个阶段可否微调？
- VGG16 默认输出 1000 类（ImageNet），但你可以修改最后一层（classifier）来输出 10 类（CIFAR-10），然后在新数据集上继续训练。
- 这个过程确实叫微调 (fine-tuning)：它是在预训练模型的基础上，进一步在新数据集上训练。通常，你会“冻结”模型的前几层（保持 ImageNet 知识不变），只训练后几层（适应新任务）。这样，模型保留了通用知识，同时学习新数据的特定模式。

- 为什么叫微调？因为你不是从头训练整个模型（那需要海量数据和计算），而是“微调”部分参数。好处：收敛更快、需要的数据少、性能更好（尤其在小数据集上）
