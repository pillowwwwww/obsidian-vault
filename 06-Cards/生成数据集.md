---
Title: 
tags: 
原始链接:
---

## 从MINE_FL框架的dataset中生成数据集
###  生成Cifar10 NonIID Dir alpha=0.1的数据集、Cifar10 NonIID Pathological 数据集两个
命令：`python generate_cifar10.py noniid balance dir 20 0.1` 
       `python generate_cifar10.py noniid balance pat 20 0`

1. [[Dirichlet分布]]中的 **concentration 参数 α（alpha）** 是一个控制分布稀疏程度（偏斜程度）的超参数。在联邦学习中使用它来模拟 Non-IID（非独立同分布）数据划分时，α 的取值直接决定了客户端之间数据分布的相似或差异程度。

假设你有 10 个类别，要把每一类的样本分配给 5 个客户端。
你可以为某个类别从 `Dirichlet(α)` 分布中采样一个长度为 5 的概率向量，比如：(p1, p2, p3, p4, p5)
![[image-4.png]]

2. “Pathological” 划分是联邦学习领域里用来模拟**极端非 IID** 场景的一种经典方案。它的核心思想：
- 强制让每个客户端只看到非常少量的类别，且各客户端看到的类别之间几乎不重合。
- 通常在 CIFAR-10 这类 10 个类别的图片数据上，把每个类别的全部样本分成若干个“碎片”（shard），再让每个客户端盲抽一定数量的不同类别碎片，使得该客户端最终只含有少数几个类别的所有样本。
- 这种做法的好处是：
- **极端非 IID**：可以测试联邦算法在“几乎无法做跨类别学习”的条件下能否收敛；
- 可复现：每个 client 只含 2 类样本，数量固定，相同配置就能得到同样的划分结果。
“Pathological”一词字面上就是“病态、异常”的意思，暗示这种划分方式并不太符合大多数现实场景（通常边缘设备会见到多个类别，只是分布不均），但很常用来做**算法鲁棒性验证**。
#### 生成的文件夹包括以下内容：
```
├── config.json          # 存储划分的配置信息（如每个客户端的样本索引、类别分布等）
├── rawdata/             # 原始的 CIFAR-10 数据包（下载并解压后的二进制/图像）
├── train/               # 按客户端分好的“训练集”子文件
├── test/                # 按客户端分好的“测试集”子文件
```

### 两种方式的对比
![[image-5.png]]
- **当你想模拟“每个客户端几乎只见到少数类别”时，选 Pathological**；
- **当你想更真实地模拟“每个客户端见到所有类别，但各类别比例不同”时，选 Dirichlet**。
在实际联邦学习实验中：
- Pathological 适用于测试算法对极端非 IID 数据的鲁棒性；    
- Dirichlet 可以方便地通过调整 α 值，得到不同程度的非 IID 情况——例如，α=0.1 时非常稀疏，α=1.0 时中等，α=10.0 时接近 IID。

### 举例：真实脚本中对应的数字
`python generate_cifar10.py noniid balance dir 20 0.1` 
`python generate_cifar10.py noniid balance pat 20 0`

将示例换回你真实的参数：
————————————————
- `num_clients = 20`
- CIFAR-10 每类一共 6000 张（50000 train + 10000 test）
- 每类先拆成 `20` 份 shards → 每 shard ≈ `6000/20 = 300` 张
- 总共 `10 × 20 = 200` 个 shards
- 然后“每个客户端恰好拿 2 个类别的所有 shard → 每个 client 得到 2 个 shard × 300 张 = 600 张    
- 20 个客户端一共拿走 `20 × 2 = 40` 个 shards，剩下 `200−40 = 160` 个 shards 被丢弃或不用，因为 `balance=True` 意味着只要保证每个 client 拿到“相同数量”（600 张）就行。
————————————————
**最后**，每个 `client_i` 下的数据分布是：
- `client_i` 的 600 张里，600 张都属于恰好两个类别中的若干混合；
- 你可以在生成目录 `Cifar10_NonIID_Pat2_Client20/` 里的 `config.json → statistic` 字段里看到哪个 client_i 拿到了哪两个类别、各类别拿了多少张（通常是 300 张 + 300 张）；
- 这些数据既有来自“原始训练集”的索引，也有来自“原始测试集”的索引，后续 `split_data()` 会把它们分到 `train/` 和 `test/` 两个子文件夹下，确保原来是测试集的样本仍然是存到 `test/client_i.npz`。
	```"statistic": [
	 [0, 0, 300, 0, 0, 0, 0, 300, 0, 0],   # client_0 拿到（类别 2：300 张, 类别 7：300 张）
	 [0, 300, 0, 0, 300, 0, 0, 0, 0, 0],   # client_1 拿到（类别 1：300, 类别 4：300）
	 … 
	]```


### 总结整个划分流程
1.融合 train+test 后，后续再“拆回” train/test
 举个简单的例子来说明：
假设：
- CIFAR-10 原始训练集的索引是：0 ~ 49999
- 原始测试集的索引是：50000 ~ 59999
你把它们合并后，得到了：
`X_all.shape = (60000, 32, 32, 3) y_all.shape = (60000,)`
然后进行了 Pathological 分配，比如 `client_0` 得到了以下 600 个样本索引：
`[100, 200, ..., 49000] + [50200, 50300, ..., 59800] 
=> 前一部分来自原 train，后一部分来自原 test`
 **`split_data(X, y)` 做的事：**
- 检查这 600 个索引中：
    - 哪些小于 50000 → 这些是原训练集的样本，归到 `train/client_0.npz`；
    - 哪些大于等于 50000 → 是原测试集样本，归到 `test/client_0.npz`
这样就完成了**训练/测试集的再拆分**，但你只做了一次统一的非 IID 分配。



## 补充：
在机器学习/深度学习领域，**大写 X** 和 **小写 y** 已经约定俗成地用来表示：
- **X** （有时写成 `X_all`、`dataset_image`、`features`）表示“全部样本的特征矩阵”（features/inputs）。在图片分类任务中，这里具体是一整个 `NumPy` 数组，形状通常是 `(N, H, W, C)`，比如 CIFAR-10 就是 `(60000, 32, 32, 3)`，前 50000 张是训练集，后 10000 张是测试集。
- **y** （有时写成 `y_all`、`dataset_label`、`labels`）表示“全部样本对应的标签向量”（targets/outputs），形状是 `(N,)`，每个元素是 0–9 之间的整数，表示该张图片所属的类别。
### balance标签？这与dir分布有什么不一样？
- 在脚本中，我们传递了 `balance=True`，意味着希望在“非 IID，但各客户端样本数大致保持平衡”（总量上尽量相近），而不是某几个客户端拿到过多样本，其他客户端拿到很少。
- 如果 `balance=False`，则客户端样本总量也可能像类别分布一样有偏斜。
