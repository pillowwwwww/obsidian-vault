---
Title: 
tags: 
原始链接:
---

## 从MINE_FL框架的dataset中生成数据集
####  生成Cifar10 NonIID Dir alpha=0.1的数据集、Cifar10 NonIID Pathological 数据集两个
命令：`python generate_cifar10.py noniid balance dir 20 0.1` 
       `python generate_cifar10.py noniid balance pat 20 0`

1. [[Dirichlet分布]]中的 **concentration 参数 α（alpha）** 是一个控制分布稀疏程度（偏斜程度）的超参数。在联邦学习中使用它来模拟 Non-IID（非独立同分布）数据划分时，α 的取值直接决定了客户端之间数据分布的相似或差异程度。

假设你有 10 个类别，要把每一类的样本分配给 5 个客户端。
你可以为某个类别从 `Dirichlet(α)` 分布中采样一个长度为 5 的概率向量，比如：(p1, p2, p3, p4, p5)
![[image-4.png]]

2. “Pathological” 划分是联邦学习领域里用来模拟**极端非 IID** 场景的一种经典方案。它的核心思想：
- 强制让每个客户端只看到非常少量的类别，且各客户端看到的类别之间几乎不重合。
- 通常在 CIFAR-10 这类 10 个类别的图片数据上，把每个类别的全部样本分成若干个“碎片”（shard），再让每个客户端盲抽一定数量的不同类别碎片，使得该客户端最终只含有少数几个类别的所有样本。
- 这种做法的好处是：
- **极端非 IID**：可以测试联邦算法在“几乎无法做跨类别学习”的条件下能否收敛；
- 可复现：每个 client 只含 2 类样本，数量固定，相同配置就能得到同样的划分结果。
“Pathological”一词字面上就是“病态、异常”的意思，暗示这种划分方式并不太符合大多数现实场景（通常边缘设备会见到多个类别，只是分布不均），但很常用来做**算法鲁棒性验证**。
### 生成的文件夹包括以下内容：
```
├── config.json          # 存储划分的配置信息（如每个客户端的样本索引、类别分布等）
├── rawdata/             # 原始的 CIFAR-10 数据包（下载并解压后的二进制/图像）
├── train/               # 按客户端分好的“训练集”子文件
├── test/                # 按客户端分好的“测试集”子文件
```

### 两种方式的对比
![[image-5.png]]
- **当你想模拟“每个客户端几乎只见到少数类别”时，选 Pathological**；
- **当你想更真实地模拟“每个客户端见到所有类别，但各类别比例不同”时，选 Dirichlet**。
在实际联邦学习实验中：
- Pathological 适用于测试算法对极端非 IID 数据的鲁棒性；    
- Dirichlet 可以方便地通过调整 α 值，得到不同程度的非 IID 情况——例如，α=0.1 时非常稀疏，α=1.0 时中等，α=10.0 时接近 IID。


### balance标签？这与dir分布有什么不一样？
- 在脚本中，我们传递了 `balance=True`，意味着希望在“非 IID，但各客户端样本数大致保持平衡”（总量上尽量相近），而不是某几个客户端拿到过多样本，其他客户端拿到很少。
- 如果 `balance=False`，则客户端样本总量也可能像类别分布一样有偏斜。




在机器学习/深度学习领域，**大写 X** 和 **小写 y** 已经约定俗成地用来表示：
- **X** （有时写成 `X_all`、`dataset_image`、`features`）表示“全部样本的特征矩阵”（features/inputs）。在图片分类任务中，这里具体是一整个 `NumPy` 数组，形状通常是 `(N, H, W, C)`，比如 CIFAR-10 就是 `(60000, 32, 32, 3)`，前 50000 张是训练集，后 10000 张是测试集。
    
- **y** （有时写成 `y_all`、`dataset_label`、`labels`）表示“全部样本对应的标签向量”（targets/outputs），形状是 `(N,)`，每个元素是 0–9 之间的整数，表示该张图片所属的类别。