[[2025-11-17]]这里先看了一下当前根据pilot的一些点：联邦+多模态+大模型+lora+adapter+moe/moa
https://chatgpt.com/c/69184cfb-0684-832a-ae60-5f8112fed7c0 这里面问了一些关于在pilot上面魔改创新点的问题，比如加ocr，把task放在图片外一圈传上去，具体在[[2025-11-15]]的tracking里面
---
现在看一下modal merging:

## 首先是Mix data or merge models? Optimizing for diverse multi-task learning：

在abstract中提到：
- 目前的模型已经被全球广泛采用，并且部署到多种应用中。偏好训练和安全措施往往过度拟合于西方中心化数据集中常见的危害，而安全协议经常无法扩展到多语言环境中。
-  多任务+多语言，每种语言引入了独特的挑战。
- 基于语言的合并，基于目标的合并很有效。
- 模型混合比weights混合更有效。

## What Matters for Model Merging at Scale?
- 比较了四种流行的合并方法——平均值、任务算术、Dare-TIES和TIES合并——对从1B到64B参数的不同模型规模进行合并。
- 在零样本上进行评估
- 当合并八个大型专家模型时，合并后的模型通常比多任务训练模型泛化得更好。
- 使用较大的模型时，可以更好地合并更多的专家模型。

## 联邦学习的模型聚合 vs 近年的 Model Merging，本质区别是什么？
> 很粗暴地说：
> * 联邦聚合 = **“训练过程中的一个优化步骤”**；
> * 模型合并 = **“训练完之后的一个参数算术/后处理操作”**。

使用时机与过程不一样
**联邦学习聚合：**
* 是**迭代过程中的一环**：
1. 服务器下发当前全局模型 (w_t)
2. 客户端在本地数据上做几步 SGD，得到 $w_t^{(k)}$
3. 服务器聚合：$w_{t+1} = \sum_k p_k w_t^{(k)}$
4. 重复多轮。
* 每一轮的本地模型都是“**从同一个当前全局模型出发的小步更新（small update around (w_t)）**”。

**模型合并：**
* 多数情况下是**一次性（one-shot）或少数几步**：
* 先分别把 experts 训练/微调到各自的收敛点；
* 合并时**不再继续访问训练数据**；
* 直接做权重平均、task vector 加法、TIES 那样的操作。
* 合并的对象通常是“**已经各自走到不同 basin 的独立最优点**”，不是围绕某个共同的当前点的小更新。

## 知乎的总结
[(99+ 封私信 / 7 条消息) 首页 - 知乎](https://www.zhihu.com/column-square)
- **在同任务上，融合后的单一模型，和融合前的各个模型相比，表现如何？** 很随机，并不好。DARE + Task-Arithmetic 貌似好一点
- 从`TIES`论文的实验来看，融合模型的OOD Generalization能力还不错，说明**融合模型在一定程度上学到了鲁棒的task解决能力**。

**其他使用场景**：
模型融合还有一些使用场景：
1. 在一次训练当中，融合多个checkpoint，以提升模型的训练效果；
2. 将融合模型作为进一步Fine-Tuning的起点，以取得更好的FT效果；
3. `Task Vector`不仅可以用于加（即模型融合），也可以用于减（即让模型遗忘某些能力）。
