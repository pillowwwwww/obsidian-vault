--- 
Title: "FedMBridge: Bridgeable multimodal federated learning"
Year: 2024
Authors: Jiayi Chen, Aidong Zhang
Tags: 

---

Zotero PDF Link: [2024-FedMBridge Bridgeable multimodal federated learning.pdf](zotero://select/library/items/CHHK4LWD)
Related::  

### Persistent Notes 
%% begin notes %% 
Write notes here! 
 %% end notes %% 
### In-text annotations
  
 <mark class="hltr-orange">"FedMBridge: Bridgeable Multimodal Federated Learning"</mark> [Page 1](zotero://open-pdf/library/items/CHHK4LWD?page=1&annotation=6UVA4859) 
 
 
 

MFL将不同模态合并到PFL系统是一个重要的研究 [Page 1](zotero://open-pdf/library/items/CHHK4LWD?page=1&annotation=3QA958HT) 
 
 
 <mark class="hltr-red">"encourage knowledge sharing"</mark> [Page 1](zotero://open-pdf/library/items/CHHK4LWD?page=1&annotation=DNY4CDHJ) 
 
 
 <mark class="hltr-red">"Yu et al., 2023) h"</mark> [Page 1](zotero://open-pdf/library/items/CHHK4LWD?page=1&annotation=5F3QY9QY) 
 
 
 <mark class="hltr-red">"(1) Task complexity difference. Due to personalization, clients may vary greatly in their complexity of modeling the inter-modal interactions, with some local tasks being more complex than others. In this situation, it is essential for different clients to employ diverse neural network sizes or even utilize varied network families that align with their personal data distributions. (2) Multimodal pattern difference. Studies in Multimodal Fusion (Atrey et al., 2010; Gao et al., 2020) have demonstrated that the patterns of inter-modal interactions can also shift across clients, necessitating distinct mechanisms for effective learning (Atre"</mark> [Page 1](zotero://open-pdf/library/items/CHHK4LWD?page=1&annotation=8TXDAHMP) 
 
 
 <mark class="hltr-black">"Different from traditional MFL that can be solved by manual block split, in AMFL we have no prior knowledge on how heterogeneous architectures are correlated with each other. Therefore, the unique challenge of AMFL, which is different from traditional MFL, is how to employ an automatic way to tackle the architecture gap during knowledge sharing among statistically-heterogeneous and architecture-heterogeneous clients."</mark> [Page 2](zotero://open-pdf/library/items/CHHK4LWD?page=2&annotation=IWMHY7UE) 
 
 
 <mark class="hltr-black">"feature-sharing methods"</mark> [Page 2](zotero://open-pdf/library/items/CHHK4LWD?page=2&annotation=EEMVGRDK) 
 
 
 <mark class="hltr-black">"implicit parameter-sharing PFL framework"</mark> [Page 2](zotero://open-pdf/library/items/CHHK4LWD?page=2&annotation=K3RK8HRA) 
 
 
 <mark class="hltr-orange">"Recently, there has been significant attention towards adapting PFL to scenarios where local models have diversified structures and sizes, particularly in budget-limited or personalized-use contexts. I"</mark> [Page 2](zotero://open-pdf/library/items/CHHK4LWD?page=2&annotation=4WBRH8R6) 
 
 
 <mark class="hltr-orange">"n pursuit of addressing architecture heterogeneity,"</mark> [Page 2](zotero://open-pdf/library/items/CHHK4LWD?page=2&annotation=QJS3C8M6) 
 
 
 <mark class="hltr-orange">"Feature-sharing PFL frameworks have been widely adopted as they naturally bypass this challenge through knowledge distillation (see above for details)."</mark> [Page 3](zotero://open-pdf/library/items/CHHK4LWD?page=3&annotation=XKVUK33Q) 
 
 
 <mark class="hltr-orange">"Multimodal Federated Learning (MFL)."</mark> [Page 3](zotero://open-pdf/library/items/CHHK4LWD?page=3&annotation=RJINWUPV) 
 
 
 <mark class="hltr-red">"; Yu et al."</mark> [Page 3](zotero://open-pdf/library/items/CHHK4LWD?page=3&annotation=DSRVZJ53) 
 
 
 

这两个部分共同构成了联邦学习的优化目标，即在最小化各自损失的同时，通过正则项 R 来促进模型间的协同学习。 [Page 3](zotero://open-pdf/library/items/CHHK4LWD?page=3&annotation=L7LH9NAW) 
 
 
 

R(⋅) 是一个函数，其输入是所有客户端的模型参数 (θ1,θ2,…,θN) [Page 3](zotero://open-pdf/library/items/CHHK4LWD?page=3&annotation=ZJRH62ZU) 
 
 


%% Import Date: 2025-05-15T16:11:23.754+08:00 %%
