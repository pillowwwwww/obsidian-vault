标题：Pruning as Alignment: Enhancing One-Shot Federated Generalization via Gradient Sensitivity
或者
**Semantically-Anchored Pruning (SAP):** Enabling One-Shot Federated Generalization via Gradient Sensitivity (语义锚定剪枝：通过梯度敏感度实现单次通信联邦泛化)
## 代码：
算法对应b

---
讲个故事：我们需要把 **One-Shot FL (骨架)**、**Domain Generalization (灵魂)** 和 **Pruning (手段)** 完美融合。

- 背景：我们处于多模态大模型时代，数据分散在各地（FL），且通信极其昂贵。因此，**One-Shot FL（单次通信）** 是刚需。
- 冲突：在 One-Shot 场景下直接 Merge，因为没有后续的微调修正，**异构的视觉参数（Visual Parameters）会发生剧烈冲突**（引用 LoRM 的“不定方程”理论，加实验一配图）。
- 假设：我们认为，这种冲突的本质是 **视觉模态的过拟合** 
		- Client A 的参数里混入了“油画笔触特征”。
		- Client B 的参数里混入了“素描线条特征”。
		- **这些特征对于“语义理解（识别是一只狗）”来说，都是噪音。**
- Insight：- 文本模态（Text Encoder）是高度稳定的（语义锚点）。
	- **剪枝不仅仅是压缩，更是一种“对齐”手段。** 通过剪掉那些对“图文匹配”没有贡献的视觉参数，我们实际上是在**强行对齐**视觉和文本，剔除风格噪音。
- **结论 (Conclusion):** 剪完之后的模型，虽然参数变少了，但**更纯粹**了。因此，它在未见过的domain上，泛化能力反而吊打所有未剪枝的方法。
---
注意： 需要定义为未见域，而不是未见任务，Pilot是未见任务，但是合并难度太高了。RobustMerge确实用了 "Unseen Task" 这个词，但你看它选的数据集：ImageNet-R（ImageNet的变种）、TabMWP。本质上这更多是 **Out-of-Distribution (OOD)** 数据，也就是**域泛化**。

---
以下是完整报告：

### **1. 问题定义与动机 (Problem Setup & Motivation)**

场景设定：

我们关注 One-Shot Federated Domain Generalization (OS-FDG) 场景。

- 存在 $K$ 个异构客户端，每个客户端 $k$ 拥有来自特定领域 $D_k$（如 Art, Sketch, Cartoon）的私有数据。
    
- 我们的目标是训练一个全局模型，使其在**完全未见过的目标领域** $D_{unseen}$（如 Real Photo）上具有强大的泛化能力。
    
- **约束：** 为了通信效率和隐私，每个客户端仅与服务器进行**一次通信（One-Shot）**，且服务器**无法访问客户端的私有数据**。
    

核心洞察 (Core Insight):

在多模态模型（如 CLIP）的参数高效微调（PEFT/LoRA）中，我们发现视觉模态的参数存在严重的“域过拟合”现象。

- 客户端学习到的视觉 LoRA 参数 $\Delta W_k$ 中，混杂了大量的**“非因果风格噪音”**（Non-Causal Style Noise，例如油画的笔触、素描的线条）。这些参数虽然降低了本地 Loss，但在语义层面是无效甚至有害的。
    
- 直接平均（FedAvg）会将这些冲突的噪音强行混合，破坏模型的泛化能力。
    
- **破局点：** 文本模态（Text Encoder）具有高度的语义稳定性。我们可以利用文本作为**“语义锚点（Semantic Anchor）”**，通过极少量的公共数据，筛选出视觉参数中真正贡献于语义理解的部分。
    

---

### **2. 方法论详细流程 (The Proposed Method)**

我们的方法分为三个阶段：**Local Training（本地训练）** $\rightarrow$ **Server-Side Semantic Filtering（服务端语义过滤）** $\rightarrow$ **Global Aggregation（全局聚合）**。

#### **阶段一：本地异构训练 (Local Heterogeneous Training)**

每个客户端 $k$ 在其私有领域数据 $D_k$ 上独立微调 CLIP 的视觉编码器（引入 LoRA 模块）。
- 目标：$\min_{\Delta W_k} \mathcal{L}_{task}(D_k; \theta_{fixed}, \Delta W_k)$。
    
- 输出：得到包含特定领域知识（及噪音）的本地参数 $\Delta W_k$。
    
- **One-Shot 上传：** 客户端将 $\Delta W_k$ 发送至服务器。
#### **阶段二：基于梯度的语义剪枝 (Gradient-Based Semantic Pruning)** —— **(核心创新)**

服务器端维护一个极小的**公共锚点数据集 (Public Anchor Set)** $D_{pub}$（例如 16~32 张来自 COCO 的通用图片和文本），作为对齐的基准。

对于每一个接收到的客户端参数 $\Delta W_k$，服务器执行以下“体检”步骤：

1. 前向传播 (Semantic Alignment Check):
    
    将 $\Delta W_k$ 加载到冻结的 CLIP 模型中。输入公共锚点数据 $D_{pub}$，计算视觉特征 $V$ 与文本特征 $T$ 的对齐损失 (Alignment Loss)：
    
    $$\mathcal{L}_{align} = 1 - \text{CosineSimilarity}(V_{img}, T_{txt})$$
    
    - _这一步的物理含义：我们在测试这组参数是否能正确理解“通用图片”的语义，而不是特定的“油画”或“素描”。_
        
2. 反向传播与敏感度计算 (Sensitivity Calculation):
    
    计算对齐损失相对于 LoRA 参数的梯度，并利用 一阶泰勒展开 (First-Order Taylor Expansion) 估算每个参数的重要性得分（Saliency Score）：
    
    $$S_{k, i} = \left| \Delta W_{k, i} \cdot \frac{\partial \mathcal{L}_{align}}{\partial \Delta W_{k, i}} \right|$$
    
    - **高分 ($S_{high}$):** 该参数极大地促进了视觉与文本的语义对齐，属于**“语义核心参数”**。
        
    - **低分 ($S_{low} \approx 0$):** 该参数对通用语义对齐没有贡献。这意味着它要么是死参数，要么是仅服务于本地特定风格（如笔触纹理）的**“过拟合噪音”**。
        
3. 语义剪枝 (Pruning as Alignment):
    
    根据得分 $S_{k}$，生成一个二进制掩码 $M_k$，将得分最低的 $\rho\%$ 参数置为 0：
    
    $$\hat{\Delta W}_k = M_k \odot \Delta W_k$$
    
    - _效果：我们成功地从“油画模型”中剔除了“油画味”，只留下了“内容理解”的能力。_
        

#### **阶段三：缩放与合并 (Rescaling & Merging)**

由于剪枝导致了参数能量（Magnitude）的损失，为了保持模型的表达能力，我们引入能量补偿机制（参考 RobustMerge 或简单的 Scaling）：

$$\Delta W_{global} = \frac{1}{K} \sum_{k=1}^{K} \text{Scale}(\hat{\Delta W}_k)$$

最终得到的 $\Delta W_{global}$ 是一个去除了风格噪音、保留了语义共性的高鲁棒性模型。

---

### **3. 逻辑严密性论证 (Why it works?)**

在这一节，我们要向审稿人解释为什么这个方法是合理的。

- 从“风格-内容”分离的角度：
    
    在异构联邦学习中，每个客户端的模型都可以看作是 $Knowledge_{semantic} + Noise_{style}$。
    
    传统的 FedAvg 试图取平均值：$\frac{Style_A + Style_B}{2}$，这在数学上是无意义的，会导致特征空间坍塌。
    
    我们的方法通过 $D_{pub}$（它不包含 Style A 或 Style B 的特征）作为过滤器，利用梯度敏感度让 $Noise_{style}$ 显形（因为它们对 $D_{pub}$ 的语义对齐无贡献），从而精准剔除噪音，实现 $Knowledge_{semantic}$ 的纯净聚合。
    
- 从“桥梁”的角度：
    
    我们利用梯度（Gradient）作为桥梁，将特征空间（Feature Space）中的语义一致性约束，传递回参数空间（Parameter Space），实现了对参数的物理修剪。这比 RobustMerge 这种仅基于参数大小的“盲剪”具有显著的理论优越性。
    

---

### **总结给审稿人的话 (Takeaway)**

> "Unlike previous One-Shot FL methods that rely on heavy knowledge distillation or blind parameter averaging, we propose **Pruning as Alignment**. By leveraging a small public anchor set to compute gradient sensitivity, we explicitly identify and prune domain-specific parameter noise. This transforms the global aggregation from a 'noisy mix' into a 'semantic consensus', enabling superior generalization to unseen domains."

----
## 存在问题：
1. one-shot FL的定义可能是只能进行一次通信的联邦。可能不是我们这个场景的含义
2. 未发表论文《GradPruner: Gradient-Guided Layer Pruning Enabling Efficient Fine-Tuning and Inference for LLMs》这篇论文的数据集可以抄一下
---
## 待看论文:
### 1.  剪枝/稀疏化中：用梯度/敏感度筛参数

这块是你问题里“敏感度 = 参数重要性”最直接的用法之一。
#### 3.1 NeurIPS 2023: Optimal Parameter and Neuron Pruning (OPNP)

- **论文**：_Optimal Parameter and Neuron Pruning for Out-of-Distribution Generalization_，NeurIPS 2023 [NeurIPS 会议论文集+1](https://proceedings.neurips.cc/paper_files/paper/2023/file/a4316bb210a59fb7aafeca5dd21c2703-Paper-Conference.pdf)
    
- **做法**：
    
    1. 对所有训练样本求梯度，并对每个参数/神经元的梯度在数据上取平均 → 得到**参数敏感度**。
        
    2. 把**极大**或**接近 0** 敏感度的参数和神经元剪掉。
        
- **直觉**：
    
    - 过大敏感度 → 过拟合、OOD 表现差；
        
    - 过小敏感度 → 基本没贡献，可以安全剪。
        
- **特点**：训练后、近似 training-free，用的就是你说的“梯度反映参数对任务的敏感度”。
    

#### 3.2 LLM 剪枝：Pruner-Zero 等

- **Pruner-Zero: Evolving Symbolic Pruning Metric from Scratch**（ICLR 2024）
    
    - 系统性地探索多种梯度/Hessian/激活等组合的“剪枝打分函数”，本质上就是在搜哪种**参数重要性度量**最好用。[GitHub](https://raw.githubusercontent.com/mlresearch/v235/main/assets/dong24b/dong24b.pdf?utm_source=chatgpt.com)
        
- 一些近年来的大模型剪枝工作（包括 Hessian-based、SVD-based rank allocation 等）都反复强调：
    
    - “怎样的敏感度指标更稳定、更可迁移”，从单纯的梯度大小走向“梯度 + 曲率 + 结构信息”的混合。[ACL Anthology+1](https://aclanthology.org/2025.coling-main.243.pdf?utm_source=chatgpt.com)
### 2.ACL Findings 2025: Sens-Merging

- **论文**：_Sens-Merging: Sensitivity-Guided Parameter Balancing for Task Vector Merging_，Findings of ACL 2025 [ACL Anthology+1](https://aclanthology.org/2025.findings-acl.984.pdf)
    
- **场景**：多任务 fine-tuned 模型的 task vector 合并。
    
- **两层敏感度分析**：
    
    1. **层内敏感度（layer-wise sensitivity）**：
        
        - 在每个任务特定模型中，用 calibration data 的梯度信息计算 sensitivity score，识别“对该任务最关键”的层。[arXiv+1](https://arxiv.org/html/2502.12420v2?utm_source=chatgpt.com)
            
    2. **跨任务敏感度（cross-task sensitivity）**：
        
        - 基于 logits 对齐，衡量不同任务模型之间的相似度/冲突度，进而调整 task vector 的 scaling。[ACL Anthology](https://aclanthology.org/2025.findings-acl.984.pdf)
            
- **结果**：
    
    - 相当于给每个任务、每一层一套“权重系数”，在合并时对**更敏感的层/任务加权更大**，从而避免 naive average 导致的灾难性干扰。
        

> 这篇几乎是你“LoRA / adapter + model merging + 参数敏感度”构想的直接前驱，只不过它还没进 FL setting，也没做多模态 CLIP/MLLM。

### 3. 联邦学习 + PEFT：用敏感度选层、选参数
EMNLP 2024: FibecFed（Fisher 信息 + 敏感度的 FL curriculum）
- **论文**：_Fisher Information-based Efficient Curriculum Federated Learning (FibecFed)_，EMNLP 2024 [ACL Anthology+1](https://aclanthology.org/2024.emnlp-main.587.pdf)
    
- **两种“敏感度”用法**：
    
    1. **样本难度（curriculum）**：用 Fisher 信息衡量样本的“信息量/难度”，先学简单再学难。
        
    2. **稀疏参数更新**：
        
        - 用敏感度-based 方法选**重要层**做全局聚合；
            
        - 用 Fisher-based 指标选**重要参数**参与更新，其余参数冻结。[ACL Anthology](https://aclanthology.org/2024.emnlp-main.587.pdf)
            
- 和你想做的事的对齐点：
    
    - 他们已经在 FL 里引入“**敏感度驱动的稀疏更新 + PEFT 层选择**”；
        
    - 但他们主要还是在 task-increment / domain-increment 的 NLP 上，并没有深入到多模态 + unseen task merging。
        

> 换句话说：**“参数敏感度驱动的联邦 PEFT 稀疏更新”已经有人做了，但“用敏感度来指导 LoRA/adapter 的跨任务合并 + 未见任务初始化”的方向还很空（除了下面这篇 Sens-Merging 属于 centralized setting）。**


---
## 结论：
实验证明，这样的CLIP基座设计是不可行的。
即使我进行了攻击（real world这个domain学的全都是完全错误的label）但是最后的准确率不受到影响。  【再去思考一下那个加和除以4的是怎么算的】
它强大的泛化能力和zero-shot能力，以及训练数据是4亿数据对。很难在未见域上能力提升了，它已经够强了