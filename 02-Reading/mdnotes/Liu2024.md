# 🔤 基于费舍信息的高效 Curriculum 联邦学习与大型语言模型 (2024, Liu) ()

**原名：**Fisher information-based efficient curriculum federated learning with large language models

**译名：** 基于费舍信息的高效 Curriculum 联邦学习与大型语言模型

**作者：**Liu et al.

**期刊：**

**IFQ：**

**DOI：**[10.48550/arXiv.2410.00131](https://doi.org/10.48550/arXiv.2410.00131)

**发表时间：**2024-10-18

**本地链接:**[2410.00131v2.pdf](zotero://open-pdf/0_SWVPVEMJ)

**摘要翻译：**

> 联邦学习（Federated Learning, FL）是一种在分布式数据上协同训练模型的范式，可以用来在不聚合各设备原始数据的前提下微调大语言模型（Large Language Models, LLMs）。然而，由于 LLM 规模巨大，训练数据规模也随之剧增，导致计算与通信开销极其庞大。同时，训练数据通常是非独立同分布（non-IID）的，这要求每个设备进行自适应的数据处理。即便采用低秩适配（Low-Rank Adaptation, LoRA）大幅减少微调时需要更新的参数量，将所有层的低秩参数都在联邦场景中传输仍然耗时难以承受。  
> 本文提出一种基于费舍信息（Fisher Information）的高效课程联邦学习框架 FibecFed。框架包含两个新方法：**自适应联邦课程学习**与**高效稀疏参数更新**。第一，我们提出基于费舍信息的样本难度评估方法，在每个设备内部自适应地抽样训练数据，从而提升联邦微调的有效性。第二，我们在 LoRA 设置下，动态选择参与全局聚合的关键网络层以及本地更新的稀疏参数集合，从而提高联邦微调的效率。基于 10 个数据集的大量实验表明，与 17 个基线方法相比，FibecFed 在准确率上最多提升 45.35%，在微调速度上最多提升 98.61%。

---

### 1. 方法动机

#### 1a) 为什么提出这个方法？

- LLM 在 FL 场景下微调有三大痛点：
    
    1. **模型巨⼤** → 全量参数微调 + 频繁上传/下载 = 极高通信 & 计算开销。
    2. **数据 non-IID** → 不同客户端数据分布差异大，简单随机采样对训练效率和泛化都不友好。
    3. **现有 PEFT（LoRA / prompt tuning）在 FL 下仍然很贵**：即使只微调 LoRA，也要在所有层上传 LoRA 参数，通信仍然“爆炸”。

作者想要的是：**在不牺牲性能的前提下，显著减少：①要训练的样本，②要更新的层，③要更新的神经元/LoRA 参数**，从而降低时延与通信量。

#### 1b) 现有方法的不足

1. **课程学习（Curriculum Learning）方向**
    
    - 多数方法用 _启发式难度指标_（如序列长度、静态特征）或简单模式预测样本难度。
    - 这些指标**与模型真实训练状态脱节**，在 non-IID 的 FL 环境下尤其不靠谱。
    - 有人用“当前损失值”做难度，但只反映瞬时拟合，不直接刻画“对泛化是否有帮助”。
2. **模型压缩 / 稀疏训练方向**
    
    - 剪枝与稀疏训练可以降低开销，但：
        
        - 剪枝率不好选，剪多了性能崩，剪少了没节省多少。
        - 很多方法按简单标准（如权重大小）选重要神经元 → 容易带来明显精度损失。
3. **PEFT + FL 方向（Adapter, LoRA, Prompt 等）**
    
    - Prompt tuning（FedPrompt 等）通信量低，但性能明显落后。
    - LoRA 只更新低秩矩阵，但**仍对所有层做 LoRA & 同步**，在 LLM 上通信成本仍然不小。

简而言之：**大家要么在数据选择上很粗糙，要么在参数选择上很粗糙，要么省通信但牺牲太多性能。**

#### 1c) 研究假设 / 直觉

论文的核心直觉可以压缩为两点：

1. **费舍信息（Fisher Information, FI）可以统一刻画“样本难度”和“参数重要性”**：
    
    - FI 大 → 模型对该样本/参数更敏感，对损失和泛化影响更大。
2. **只用“对训练真正有用的数据 + 真正重要的层/神经元”来训练，就能在保持性能的同时，大幅减少通信和计算。**

---

### 2. 方法设计（FibecFed Pipeline）

FibecFed = **FI-based Curriculum FL + FI-based Sparse Parameter Update**（在 LoRA 框架下）。整体包含两个阶段：**初始化阶段** & **联邦微调阶段**。

#### 2a) 整体流程：输入 → 处理 → 输出（逐步拆开）

**输入**

- 预训练好的 LLM (M)，例如 RoBERTa-LARGE 或 LLaMA-7B。
- 每层加上 LoRA 模块（低秩矩阵 (A_l, B_l)），只更新 LoRA 参数集合 (P)。
- K 个客户端，各自持有 non-IID 文本任务数据集 (D_k)。
- 一个中心参数服务器（parameter server）。

---

#### 阶段一：初始化（Initialization Phase）

**Step 1：在每个客户端用 FI 评估样本难度，并排序（做课程）**

1. 在客户端 k 上，对每个 batch (B_j \subset D_k)：
    
    - 计算该 batch 上损失对 LoRA 参数的梯度 (\nabla \log p_k(s_i))。
    - 用“梯度外积的对角线”近似 FI 对角阵（Empirical FIM）：  
        [  
        \tilde F_i = I \odot (\nabla \log p_k(s_i), \nabla \log p_k(s_i)^\top)  
        ]  
        实际实现中就是“**梯度元素平方**”再做平均。
    - 将对角元素求和（trace）作为**样本/批次的难度得分**：FI 大 → 样本难。
2. 对所有 batch 的难度得分排序，得到从“易 → 难”的序列。
3. 在后续训练回合 t 中，客户端只取前 (B_k^t) 个最容易的 batch 来训练，其中 (B_k^t) 随着 t 增大而增大（即先用更少、更容易的数据，逐渐引入更难/更多数据）。具体增长策略在附录里由参数 (\alpha,\beta) 控制。

---

**Step 2：计算每层“重要性”，选择 Global Aggregation Layers（GAL）**

目标：**只让“最敏感/最重要”的几层参与跨客户端同步**，其余层只做本地更新或直接冻结，以减少通信。

1. 对每个样本 (s_i)，构造一个**对输入加噪后的对比样本** (s_i + \epsilon_i)：
    
    - 在 (|\epsilon_i|_p < \gamma) 的约束下，找到使损失增大最多的扰动：  
        [  
        \epsilon_i = \arg\max_{|\epsilon|_p<\gamma} \left[L_k(s_i + \epsilon)-L_k(s_i)\right]  
        ]
    - 用一阶泰勒展开和对偶问题求解，得到近似的最坏扰动 (\epsilon_i^*)。
2. 对于 LLM 的每一层 (l)，计算在原样本与加噪样本下的输出嵌入 (h_l(s_i)) 和 (h_l(s_i+\epsilon_i^_)) 的 Frobenius 范数相对差：  
    [  
    F_l(s_i) = \frac{|h_l(s_i+\epsilon_i^_)|_F - |h_l(s_i)|_F}{|h_l(s_i)|_F}  
    ]  
    这就是**层敏感度指标**：输入稍微扰动，该层输出变化越剧烈 → 该层越重要。
3. 在客户端 k 上，对本地数据求平均，得到该客户端视角下的层重要性 (I_l^k)。再在服务器端按样本数加权平均，得到**全局层重要性 (I_l)**。
4. **选择要同步的层数**（“lossless”策略）：
    
    - 对本地损失函数的 Hessian 做特征分解，看特征值序列中何处分割可以保证 Lipschitz 条件，从而在只保留一部分方向时近似“无损”。据此计算**期望该客户端需要同步的层数 (N_k^*)**。
    - 汇总所有客户端后，根据一个超参数 (\mu) 确定全局需同步的层数 (N^*)，再从所有层中选出 FI 重要性 (I_l) 最大的 (N^*) 层作为 **GAL**。
5. 将 GAL 的 LoRA 参数初始化状态广播到所有客户端。

---

**Step 3：在每个客户端选择“本地可更新参数子集”**

目标：**在 GAL 以外的层里，只训练一小部分最重要的神经元/LoRA 通道，其余直接冻结。**

1. 在前 (T') 轮中，客户端 k 对每一层 l 计算 FI 的移动平均：  
    [  
    F_k^t = \gamma F_k^{t-1} + (1-\gamma)\tilde F_k  
    ]  
    其中 (\tilde F_k) 是第 t 轮上的 FI 对角近似。
2. 对每个神经元 μ，在该层对应的 FI 对角线上做行聚合（将该神经元在权重矩阵中对应的对角元素加总），作为神经元重要性分数 (\int_\mu^{k,l})。
3. 再次用 Hessian-eigengap / Lipschitz 的“无损”思想，确定该层可更新的比例 (\rho_{k,l})，从而在该层中选出前 (\rho_{k,l}) 部分最重要的神经元，作为**本地更新参数集合**；其余参数（包括部分 LoRA 行/列）在训练中保持冻结。

输出：

- 每个客户端：
    
    - 样本难度排序 + 课程计划（哪些 batch 先训，哪些后训）；
    - 各层神经元的重要性排序和“可更新掩码”；
- 服务器端：
    
    - 一组全局聚合层 GAL 的 LoRA 参数。

---

#### 阶段二：联邦微调（Fine-tuning Phase）

每一轮 t 的流程如下：

1. **服务器采样部分客户端**（如 100 个中的 10 个）。
2. **服务器 → 客户端广播**：
    
    - 将当前 GAL 的全局 LoRA 参数 (P^{t-1}_{GAL}) 发送给被选中的客户端，让它们覆盖本地相应层的 LoRA 参数。
3. **客户端本地训练（带课程 + 稀疏更新）**：
    
    - 客户端按照课程策略，从“易 → 难”的 batch 中选出当前轮允许的 (B_k^t) 个 batch。
    - 只对：
        
        - ① GAL 中所有 LoRA 参数，
        - ② 非 GAL 中被标记为“可更新”的 LoRA 神经元/通道  
            进行梯度更新；其他参数都冻结。
4. **客户端 → 服务器上传**：
    
    - 每个客户端只上传 GAL 中更新后的 LoRA 参数；非 GAL 层只做本地个性化更新，不参与聚合。
5. **服务器端聚合**：
    
    - 对收到的 GAL 参数执行 FedAvg 式加权平均，得到新的 (P^t_{GAL})。

多轮迭代后，得到：

- 一个在 GAL 上共享的全局 LoRA，
- 每个客户端拥有自己本地的稀疏 LoRA 子网络。

---

#### 2b) 模型结构与各模块作用

1. **LLM 主干（Backbone, 冻结）**
    
    - 例如 RoBERTa-LARGE / LLaMA-7B，只做前向，不更新权重。
2. **LoRA 模块**（每层）
    
    - 原权重 (W_o^l) 被拆成：  
        $$[￼h^l = W_o^l x + B_k^l A_k^l x￼] $$
    - 只对 (A_k^l, B_k^l) 做更新；即 PEFT（参数高效微调）。
3. **Curriculum 模块（客户端侧）**
    
    - 用 FI 对每个 batch 的“信息含量/难度”打分，用于决定训练顺序和每轮参与训练的 batch 数量。
4. **GAL 选择模块（服务器 + 客户端侧）**
    
    - 利用“输入扰动 + Frobenius norm 差异”衡量每一层对输入扰动的敏感度，结合 Hessian 分析选出最该同步的层。
5. **本地稀疏更新模块（客户端侧）**
    
    - 用 FI 的移动平均衡量每个神经元的重要性，只训练重要的一小部分神经元（LoRA 通道），其余冻结。

这些模块通过“**统一使用 FI 作为信号**”绑定在一起：同一个 FI 指标既驱动“选样本”的 curriculum，又驱动“选层 + 选神经元”的 sparse update。

---

#### 2c) 关键公式/算法的通俗解释

- **FI 对角近似**：
    
    - 真实的 FIM 是“梯度外积”的矩阵，计算昂贵；
    - 他们只取对角线（即每个参数的梯度平方），既降低复杂度，又保留“对该参数敏感不敏感”的信息。
- **样本难度 = FI trace**
    
    - 对角元素求和越大，说明这批样本让很多参数的梯度都很大 → 样本“难”，信息量大。
    - 课程学习里先用“低 FI”的（易样本）让模型稳定收敛，再逐渐引入高 FI 样本。
- **层敏感度：扰动输入 → 看层输出变化幅度**
    
    - 若在小扰动下该层输出变化巨大，说明该层对输入微小变化极敏感，代表它在表征中起关键作用。
- **Hessian-eigengap + Lipschitz“无损选层/选神经元”**
    
    - Hessian 的特征值大致对应“哪些方向的损失曲面更陡”。
    - 找到一个分界点，使得只保留前若干方向（对应最陡的方向）仍能保证损失变化被 Lipschitz 常数控制 → 理论上“近似无损”。
    - 用这个比例来决定有多少层/多少神经元需要更新，其余可以冻结而不显著损伤性能。

---

### 3. 与其他方法对比

#### 3a) 与主流方法的本质区别

1. **与 Prompt Tuning / LoRA-FL 对比**
    
    - Prompt / LoRA 方法：要么只改输入提示，要么给所有层都加 LoRA，再做全层同步。
    - FibecFed：
        
        - **不对所有数据一视同仁，而是 FI-guided 选样本；**
        - **不对所有层/神经元一视同仁，而是 FI-guided 选 GAL + 稀疏神经元。**
2. **与传统 Curriculum Learning 对比**
    
    - 传统 CL 不看模型参数，只根据数据的固定属性或启发式分数决定难度。
    - FibecFed 把难度定义为“**该样本对当前 LoRA 参数的 FI**”，是**模型状态相关、训练过程自适应**的。
3. **与剪枝/稀疏 FL 对比**
    
    - 传统剪枝：按权重大小或简单指标 prune；稀疏 FL 常在训练过程动态稀疏，但指标粗糙。
    - FibecFed：**从损失敏感性（FI + Hessian）出发**选层/选神经元，目标是“在理论上尽量无损”的稀疏化。

#### 3b) 创新点

- 在 FL + LLM + LoRA 场景下，**统一用 Fisher 信息同时驱动：**
    
    1. 自适应课程（样本选择）
    2. 全局同步层选择（GAL）
    3. 本地稀疏参数选择（神经元级）
- 提出**基于 Hessian-eigengap + Lipschitz 的“lossless 层/参数选择”框架**，从理论上论证在有限同步/稀疏的情况下尽量不损失效果。
- 在 10 个 NLP 任务 + 17 个基线的系统实验中，展示了在**同时提升精度与速度**的情况下，通信开销也明显下降。

#### 3c) 适用场景

- 典型场景：
    
    - 客户端数据 non-IID 且模型非常大（LLM），
    - 有一定算力，但对**训练时延 + 通信开销**比较敏感，
    - 希望在**保持甚至提升性能的前提下**减少更新量。
- 不太适用：
    
    - 超级严格的通信约束（比 prompt-only 还苛刻），那可能还是 prompt FL 更适合。
    - 完全去中心化（无 server）或复杂拓扑网络（环、网格）下，本文方法还未适配。

#### 3d) 方法对比表（高层视角）

|维度|Prompt-FL (FedPrompt等)|全层 LoRA-FL|稀疏FL/剪枝FL|**FibecFed**|
|---|---|---|---|---|
|训练对象|提示向量/前缀|所有层 LoRA|全模型但部分权重为0|LoRA 中的部分层+部分神经元|
|数据选择|随机/简单规则|随机|随机|**FI-驱动课程选样本**|
|层选择|固定（多为 embedding / prompt）|所有层|视剪枝策略而定|**FI + 敏感度选 GAL**|
|神经元/通道选择|无|无|基于权重大小等|**FI + Hessian 无损选神经元**|
|通信开销|最低|最高|中等|**介于 Prompt 与全层 LoRA 之间**|
|性能（文中实验）|相比 FibecFed 明显偏低|较好|不稳定|**最高/接近最高**|
|适配 non-IID 能力|一般|一般|较好（个性化）|**较好 + 课程 + 个性化**|
|复杂度|低|中|中-高|**中-高（需额外算 FI/Hessian 近似）**|

---

### 4. 实验表现与优势

#### 4a) 实验设置

- **环境**：
    
    - 1 个参数服务器 + 100 个客户端，每轮随机选 10 个参与更新。
- **模型**：RoBERTa-LARGE 与 LLaMA-7B。
- **任务**：10 个 NLP 数据集（QNLI, SST-2, CoLA, MRPC, RTE, BoolQ, MPQA, Subj, TREC, MR）。
- **对比方法**：
    
    - Adapter, FedPrompt, P-tuning v2, IDPG, ATTEMPT, LPT, LoRA, Shortformer, VOC, SLW, PFedGate, FedDST, SE, FedALT, sLoRA, AdaLoRA, Delta-LoRA 共 17 个。

#### 4b) 关键结果（代表性数字）

- **RoBERTa-LARGE 上的平均准确率**：
    
    - 最强基线（例如 sLoRA / Delta-LoRA）约 86.6–86.7%。
    - **FibecFed：88.31%，平均提升约 1.6–1.7 个百分点。**
- 单任务上，最大提升可达：
    
    - 相比 Adapter：最高 +45.35% 准确率。
    - 相比其它 LoRA/Prompt/CL/个性化基线：最高提升 30%+。
- **训练时间（到达相同目标精度所需时间）**：
    
    - 在多个任务上，FibecFed 相比基线最高快 **98.61%**（也就是接近 50× 速度提升）。
- **LLaMA-7B 上**（COLA, MRPC, RTE）：
    
    - Accuracy 上对 SOTA PEFT/FL 基线最高 +33.93%。
    - 时间上最高节省 ~47%。

#### 4c) 优势最明显的场景/数据集

- 在 CoLA（语法可接受性）、RTE/BoolQ（自然语言推理/问答）这类需要较强语言理解和泛化的任务上，FibecFed 对 prompt-based 和普通 LoRA-FL 的提升尤其明显。
- 在多任务平均性能和收敛时间上，FibecFed 整体处于“最右上角”（最高性能 & 最快速度）的区域。

#### 4d) 局限性

论文在“Limitations”里也非常坦诚：

1. **依赖中心服务器**：
    
    - 设计假定有一个 parameter server 做聚合；在完全去中心化拓扑（环、网格、图）下直接迁移不方便。
2. **实现复杂度**：
    
    - 需要额外计算 FI（虽然做了对角近似）以及 Hessian 的特征值（至少近似），在算力很弱的设备上可能吃力。
3. **通信开销仍高于极端轻量方法**：
    
    - 相比 FedPrompt / IDPG 等 prompt-only 方法，FibecFed 的绝对和相对通信开销最高可达其 3.5 倍左右；只是性能提升非常巨大。
4. **尚未结合更激进的剪枝/量化**：
    
    - 论文认为可以与模型剪枝、量化等压缩技术叠加，进一步减负，但目前还没做。

---

### 5. 学习与应用

#### 5a) 是否开源？关键实现步骤

- 论文正文和附录里提到实现细节（比如 H.11 Implementation），但**没有明确给出 GitHub 链接或代码开放声明**。
- 想复现的话，大致步骤是：

1. **基于现有 FL & LoRA 框架搭建基础系统**
    
    - 如：在 FedAvg / FedProx 框架上，把本地模型替换成“冻结 LLM + LoRA”。
2. **在客户端实现 FI 计算**
    
    - 反向传播时取对 LoRA 参数的梯度，做 `grad ** 2` 并求平均，形成对角 FIM。
    - 用这个 FI：
        
        - 对每个 batch 计算得分 → 排序 → 课程调度；
        - 对每个层、每个神经元做重要性打分。
3. **实现 GAL 层选择与广播**
    
    - 对每层用“扰动输入 + Frobenius norm 差值”算敏感度；
    - 加上一个 Hessian-based 比例控制（可以从简先用经验比例），选出若干层作为 GAL；
    - 服务器存储并同步这些层的 LoRA 参数。
4. **实现本地稀疏更新掩码**
    
    - 在非 GAL 层，根据 FI 移动平均 + 神经元聚合，选出一部分神经元的 LoRA 通道为“可更新”，其余梯度直接挂零。
5. **训练循环中集成课程 + 稀疏更新 + FedAvg**
    
    - 每轮：服务器选客户端 → 广播 GAL → 客户端按课程选 batch，按掩码更新 → 上传 GAL → 服务器 FedAvg。

#### 5b) 实现时需要注意的细节/超参数

- **FI 近似的数值稳定性**：
    
    - 梯度平方容易爆；需要加上 clip 或缩放。
- **课程策略参数 ((\alpha,\beta))**：
    
    - 控制每轮参与训练的 batch 数和难度上升速度。建议从“逐渐线性增加 + 保留缓冲区”起步。
- **噪声预算 (\gamma)、范数 p**：
    
    - 太大扰动会导致不稳定；论文用的是一个相对小的预算来近似“最坏扰动”。
- **动量系数 (\gamma)（用于 FI 平滑）**：
    
    - 值太小 → 噪声大；太大 → 响应慢。可类比 EMA 设置（比如 0.9～0.99）。
- **Hessian / eigengap 部分**：
    
    - 直接精确 Hessian 太贵，可以考虑：
        
        - 用 Fisher 替代 Hessian（自然梯度的常规 trick），
        - 或者在工程上把“lossless 比例”近似为经验稀疏率（比如 20%–40%），再看 ablation。

#### 5c) 迁移到其他任务的可行性与方式

- **其他文本任务**（检索、问答、多任务、多语言）：
    
    - 直接替换下游任务头即可；FI 与 LoRA 更新逻辑完全通用。
- **多模态 / CLIP-式模型**
    
    - 思路仍然可以用：
        
        - 在视觉/文本两路 LoRA 上分别计算 FI 与层/神经元重要性；
        - 在模态融合层上用 FI 衡量样本和模态的“任务信息量”；
        - 但具体实现要考虑显存和跨模态结构的差异。
- **非 NLP / CV 模型**
    
    - 只要模型是可微、可算梯度，就可以采用 FI-based 样本/参数选取思路；
    - 但 Hessian-based “无损稀疏”在非常不同的架构上可能需要重新验证。

---

### 6. 总结

#### 6a) 一句话核心思想（≤20字）

> 用费舍信息挑数据和参数来做高效联邦微调。

#### 6b) “速记版 pipeline”（3–5 步，自明，不用论文术语）

1. **先用梯度信息给每个训练样本和每一层、每个神经元打“重要性分数”。**
2. **按分数从低到高安排训练顺序，让模型先学简单样本，再学更难的样本。**
3. **只在分数最高的几层之间做跨设备参数同步，其余层只在本地使用。**
4. **在每一层中，只更新分数最高的一小部分神经元，其余神经元在训练中保持不变。**
5. **反复执行“选样本 → 选层 → 选神经元 → 本地训练 → 聚合”的循环，直到收敛。**

如果你接下来想把这个方法类比到“PEFT + 多模态 + 未见任务”那条线，我们可以直接讨论 FI-based 重要性在你自己的 CLIP/Fed-LoRA 系统里应该怎么落地，以及它和你之前设想的“merging-based 初始化”之间的关系。