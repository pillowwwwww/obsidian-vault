# 🔤 大型语言模型在异构任务和客户端资源下的联邦微调 (2024, Bai) ()

**原名：**Federated Fine-tuning of Large Language Models under Heterogeneous Tasks and Client Resources

**译名：** NeurIPS2024：FelxLoRA: 大型语言模型在异构任务和客户端资源下的联邦微调

**作者：**Bai et al.

**期刊：**

**IFQ：**

**DOI：** [10.48550/ARXIV.2402.11505](https://doi.org/10.48550/ARXIV.2402.11505)

**发表时间：**2024

**本地链接:** [2024-Federated Fine-tuning of Large Language Models under Heterogeneous Tasks.pdf](zotero://open-pdf/0_UACCVK9W)

---



---

### 0. 摘要原文翻译

**联邦学习（FL）最近被应用于大语言模型（LLM）的参数高效微调（PEFT）。虽然前景广阔，但由于客户端资源和数据分布的异构性，这带来了巨大的挑战。本研究提出了 FlexLoRA，一种简单而有效的 LLM 微调聚合方案，它缓解了传统 FL 中的“短板效应”（即资源充足的客户端被迫迁就资源最少的参与者，限制了其潜力）。FlexLoRA 允许动态调整本地 LoRA 的秩（Rank），从而促进包含更广泛、非特定任务知识的全局模型的开发。通过综合各个客户端贡献的全尺寸 LoRA 权重，并利用奇异值分解（SVD）进行权重重分发，FlexLoRA 充分利用了异构的客户端资源。涉及数千个客户端执行异构 NLP 任务和不同资源的实验验证了 FlexLoRA 的有效性，在各种异构分布下，联邦全局模型在下游 NLP 任务性能上始终优于 SOTA FL 方法。FlexLoRA 的实用性通过我们的理论分析及其与现有基于 LoRA 的 FL 方法的无缝集成得到了进一步强调，为 LLM 的跨设备、隐私保护联邦微调提供了一条路径。**

---

### 1. 方法动机 (Motivation)

#### a) 驱动力：为何做这个？

作者希望在联邦学习环境中微调大模型，但现实世界中，参与联邦学习的设备（Client）千差万别。有的可能是高性能服务器，有的可能是边缘设备。同时，不同设备处理的NLP任务也不一样（任务异构）。作者希望**物尽其用**，让强设备多出力（训练更大的参数量），弱设备少出力，最终大家都能获得一个更好的全局模型。

#### b) 现有痛点 (Pain Points)

- **短板效应（Bucket Effect）：** 传统的联邦学习（如 FedAvg, FedIT）要求所有客户端的模型结构一致。为了让弱设备也能跑起来，系统只能被迫选择最小的 LoRA Rank（例如 $r=1$ 或 $r=8$）。
    
- **资源浪费：** 那些拥有高端显卡的客户端，本可以用 $r=200$ 甚至更高来学习更丰富的特征，但被强行降级，导致潜能浪费。
    
- **泛化能力差：** 现有研究表明，低秩（Low Rank）倾向于学习特定任务的知识，而高秩（High Rank）能包含更通用的知识。强制低秩导致全局模型在未见过的任务（Zero-shot）上泛化能力不足 1111。
    

#### c) 核心假设 (Intuition)

**假设：** 如果允许每个客户端根据自己的硬件能力选择尽可能大的 LoRA Rank，并通过某种机制将这些不同尺寸的权重有效地融合，那么得到的全局模型将比“迁就弱者”的模型具有更强的泛化能力（Generalization Ability）。

---

### 2. 方法设计 (Method Design)

这是你最关心的部分。FlexLoRA 的核心在于打破了“所有客户端必须用相同 Rank”的限制，通过 **SVD（奇异值分解）** 来实现不同 Rank 权重的聚合与分发。

#### a) 方法流程 (Pipeline)

**阶段 1：本地训练 (Local Training)**

- **输入：** 客户端 $i$ 收到全局分发的 LoRA 权重参数 $B_{init}, A_{init}$（可能是截断后的）。
    
- **配置：** 客户端 $i$ 根据自己的硬件资源，确定本地的秩 $r_i$。资源越多，$r_i$ 越大。
    
- **训练：** 客户端在本地数据上训练 LoRA 矩阵 $B_l^i \in \mathbb{R}^{d \times r_i}$ 和 $A_l^i \in \mathbb{R}^{r_i \times d}$。
    
- **输出：** 训练完成后，客户端计算增量并准备上传。**注意：** 也就是上传 $B_l^i$ 和 $A_l^i$ 以及标量 $s$。
    

**阶段 2：服务端聚合 (Server Aggregation)**

- 重构全尺寸权重（这是关键）： 服务端接收到各客户端的 $B_l^i, A_l^i$ 后，不直接平均这些小矩阵（因为维度不同，没法平均），而是先计算全尺寸的 LoRA 更新矩阵 $W_l^i$：
    
    $$W_l^i = s \cdot B_l^i \times A_l^i$$
    
    这里 $W_l^i$ 的维度是 $d \times d$（即原模型权重矩阵的维度）。
    
- 加权平均： 服务端对所有客户端的全尺寸矩阵进行加权平均（权重通常基于样本量 $n^i$）：
    
    $$W_{global} = \frac{\sum_{i=1}^{m} n^i W_l^i}{\sum_{i=1}^{m} n^i}$$
    

**阶段 3：SVD 分解与重分发 (Decomposition & Redistribution)**

- SVD 分解： 服务端对聚合后的 $W_{global}$ 进行奇异值分解：
    
    $$W_{global} \approx U \Sigma V^T$$
    
    其中 $U, \Sigma, V$ 包含了全局的、融合了各方知识的信息。
    
- **按需分发：** * 对于客户端 $j$，如果它的能力只能承受秩 $r_j$。
    
    - 服务端就只截取 $U$ 的前 $r_j$ 列，$V$ 的前 $r_j$ 行，以及 $\Sigma$ 的前 $r_j$ 个奇异值。
        
    - 发送给客户端 $j$ 的新权重为：
        
        $$B_{new}^j = U_{:, :r_j} \cdot \Sigma_{:r_j, :r_j} / s$$
        
        $$A_{new}^j = V_{:r_j, :}^T$$
        
- **循环：** 客户端收到新的 $B, A$ 后作为起点，开始下一轮训练。
    

#### b) 关键模块解析

- **Full-size Reconstruction:** 这是 FlexLoRA 能兼容异构 Rank 的根本。它把不同 Rank 的“压缩包”解压成“原图”后再混合。
    
- **SVD (Singular Value Decomposition):** 充当了“智能压缩器”。它提取了聚合后的 $W_{global}$ 中最重要的特征方向（奇异值大的方向）。这样，即使只给弱客户端发前几维，也是全局模型中最精华的信息，而不是简单的随机截断。
    

#### c) 核心逻辑通俗解释

想象大家一起画一幅巨画（全局模型）。

- **传统 FL：** 规定所有人只能用铅笔（Rank=1）。
    
- **FlexLoRA：** 允许有的人用铅笔，有的人用整套油画工具（Rank=200）。
    
    - 大家画完后，把作品寄给老师（Server）。
        
    - 老师把这些画（有的简陋，有的精美）叠加融合在一起，得到一幅信息量极大的画（$W_{global}$）。
        
    - 然后老师要把这幅画发回给大家参考。
        
    - 为了发给拿铅笔的学生，老师用素描提取了画的最主要轮廓（SVD提取主成分），发给他。
        
    - 为了发给拿油画笔的学生，老师则把细节更丰富的版本发给他。
        

---

### 3. 与其他方法对比

#### a) 本质不同

- **FedAvg / FedIT:** 强制同构（Homogeneous）。所有客户端 Rank 必须一样，受限于最弱的客户端。
    
- **HetLoRA (并发工作):** 虽然也允许异构 Rank，但它使用**零填充（Zero-padding）**来对齐矩阵，然后进行平均，再进行截断。
    
- **FlexLoRA:** 使用**SVD**。SVD 提取的是信息量最大的子空间，而零填充+截断可能会丢失重要的非对齐信息。
    

#### b) 创新点

1. **SVD 聚合机制：** 首次在联邦微调中引入 SVD 来解决异构 LoRA 的聚合与分发问题，理论上比简单的截断保留了更多信息。
    
2. **理论保证：** 证明了增加客户端数量和提高 Rank 可以降低泛化误差（基于 intrinsic dimension 理论）。
    

#### d) 方法对比表

|**特性**|**FedAvg / FedIT**|**HetLoRA**|**FlexLoRA (本文)**|
|---|---|---|---|
|**Rank 设置**|必须相同 (Homogeneous)|可以不同 (Heterogeneous)|**可以不同 (Heterogeneous)**|
|**聚合方式**|直接平均参数|零填充 + 平均|**全尺寸展开 + 平均**|
|**分发方式**|原样分发|截断 (Truncation)|**SVD 分解 + 按需截取**|
|**信息保留**|完整保留 (但Rank低)|较差 (填充可能引入噪声)|**最优 (SVD保留主要成分)**|
|**计算开销**|低|中|**高 (服务端需做 SVD)**|
|**通信开销**|低|中 (需传Padding后的矩阵)|**高 (可能涉及全矩阵传输)**|

> **顾问点评（Candid Critique）：** 表格中我特意加了“通信开销”一栏。虽然论文声称高效，但在 Server 端重构 $W_{global}$ 意味着要处理 $d \times d$ 的矩阵。如果模型维度很大（例如 $d=4096$），$W_{global}$ 会非常大。虽然客户端只传 $A$ 和 $B$，但在 Server 内部的内存和计算压力是显著的，这一点论文在“System Costs”里虽然提到了参数量增加，但避重就轻地只谈了收敛轮数减少带来的总体收益，没详细谈单轮峰值开销。

---

### 4. 实验表现与优势

#### a) 实验设置

- **数据集：** Natural Instructions (1600+ NLP 任务)，Dolly-15K。
    
- **模型：** DataJuicer-1.3B (主要), LLaMA-3-8B (扩展实验)。
    
- **异构模拟：** 设置四种客户端类型（Type 1~4），Rank 分别为 8, 30, 混合, 200。
    
- **对比基线：** FedAvg, FedIT, SLoRA, HetLoRA。
    

#### b) 结果亮点

- **泛化能力（Zero-shot）：** 在未见过的客户端任务上，FlexLoRA 的 Rouge-L 分数比同构方法高出约 **1.65%** 。
    
- **特定分布优势：** 在 "Heavy-Tail-Strong"（大部分客户端都很强，Rank=200）的分布下，优势最明显，提升达 **2.15%**。这验证了“让强者多出力”确实有用。
    
- **对比 HetLoRA：** 在所有设置下都优于 HetLoRA，证明 SVD 比 Zero-padding 更有效 。
    

#### c) 局限性 (Implicit Limitations)

1. **服务端计算压力：** 每一轮都要做 SVD。对于 1.3B 模型还行，如果上到 70B 模型，权重矩阵巨大，SVD 极其耗时且吃内存。
    
2. **通信隐患：** 虽然客户端上传的是 $A$ 和 $B$，但逻辑上 Server 需要处理全量 $W$。如果为了隐私保护采用安全聚合（Secure Aggregation），这种全量展开后的加法几乎是不可能的（通信量会爆炸）。所以它很难与现有的安全聚合协议兼容。
    

---

### 5. 学习与应用

#### a) 复现关键步骤

1. **定义 LoRA：** 确保你的 LoRA 模块支持动态 Rank 初始化。
    
2. **服务端聚合器：** 不再是简单的 `state_dict` 平均。你需要写一个函数：
    
    - 接收所有客户端的 `lora_A`, `lora_B` 和 `scale`。
        
    - 执行 `W_delta = scale * (B @ A)`。
        
    - 执行加权平均 `W_global_delta += weight * W_delta`。
        
    - 执行 `U, S, Vh = torch.linalg.svd(W_global_delta)`。
        
    - 根据每个客户端的 $r$，切片 $U[:, :r], S[:r], Vh[:r, :]` 发回。
        

#### b) 训练细节建议

- **Optimizer：** FedIT 建议客户端使用 Adam 而不是 SGD 。
    
- **Rank 选择：** 论文建议“尽可能大” 。在实际应用中，你应该检测显存余量，能开多大开多大。
    
- **SVD 频率：** 论文每一轮都做 SVD。为了省时间，你可以尝试每隔几轮做一次 SVD，中间几轮用普通平均（如果 Rank 不变的话），但这需要实验验证。
    

#### c) 迁移性

- **极强：** 这个方法不限于 LoRA。任何基于矩阵分解的微调方法（如 AdaLoRA 等）只要能还原成 $W_{delta}$，都可以用这套 SVD 聚合逻辑。
    

---

### 6. 总结

#### a) 核心思想

**利用SVD聚合不同秩的LoRA更新，让强设备贡献更多通用知识。**

#### b) 速记版 Pipeline (3步法)

1. **各画各的**：客户端按自己能力（Rank大小）训练，上传增量矩阵。
    
2. **拼原图**：服务端把所有人的增量还原成完整矩阵并平均。
    
3. **取精华**：服务端对完整矩阵做 SVD 分解，按需切片发回给客户端。
    

---

顾问的最后建议 (Next Step)：

如果你打算复现这个方法，我建议你先在一个小模型（如 GPT-2 或 TinyLlama）上跑通 SVD 聚合的流程，重点关注Server 端的内存消耗。如果显存爆了，你可能需要考虑把 SVD 放到 CPU 上做，或者使用随机 SVD (Randomized SVD) 来近似，这能大幅降低计算复杂度，论文没提这个优化点，你可以试试。