# 🔤 TMLR2024: 大规模模型合并的关键因素是什么？ (2024, Yadav) ()

**原名：**What Matters for Model Merging at Scale?

**译名：** TMLR2024: 大规模模型合并的关键因素是什么？

**作者：**Yadav et al.

**期刊：**

**IFQ：**

**DOI：** [10.48550/ARXIV.2410.03617](https://doi.org/10.48550/ARXIV.2410.03617)

**发表时间：**2024

**本地链接:** [2024-What Matters for Model Merging at Scale.pdf](zotero://open-pdf/0_5Q6PRV3T)

**摘要翻译：** _模型合并旨在将多个专家模型合并为一个更强大的单一模型，提供诸如减少存储和提供成本、提高泛化能力和支持分散模型开发等益处。尽管模型合并具有潜力，但以往的研究主要集中在合并少量小型模型上。这留下了许多关于模型规模扩展效果及其与其他关键因素（如基础模型质量和专家模型数量）相互作用如何影响合并模型性能的问题。本研究系统地评估了大规模模型合并的实用性，考察了这些不同因素的影响。我们使用4种流行的合并方法——平均值、任务算术、Dare和TIES——对从1亿到64亿参数的不同规模的模型进行完全微调，并合并多达8个不同的专家模型。我们在专家的训练任务（即持有任务）和对未见过的保留任务进行零样本泛化方面评估了合并后的模型。我们的实验提供了关于模型合并及其不同因素之间相互作用的几个新见解。首先，我们发现当专家来自具有良好零样本性能的基础模型时，合并效果更佳。其次，较大的模型使合并更加容易。第三，合并始终提高泛化能力。值得注意的是，当合并8个大型专家模型时，合并后的模型通常比多任务训练的模型泛化能力更强。第四，当我们使用较大的模型时，可以更好地合并更多的专家模型。第五，不同的合并方法在较大规模下表现非常相似。总体而言，我们的研究结果揭示了模型合并的一些有趣属性，同时也指出了其一些局限性。我们希望这项研究能为未来的相关研究提供一个参考点。_

## 💡创新点

是一个实验报告，对从1B到64B参数的不同模型规模进行合并，并合并多达8个不同的专家模型。我们对合并后的模型在专家训练任务（即保留任务）和对未见过的保留任务进行零样本泛化方面进行了评估。

我们发现，

1. 当专家模型来自具有良好零样本性能的基础模型时，合并效果更佳，与预训练模型相比。
2. 其次，较大的模型使合并更加容易。
3. 第三，合并始终提高泛化能力。值得注意的是，当合并八个大型专家模型时，合并后的模型通常比多任务训练模型泛化得更好。
4. 第四，当我们使用较大的模型时，可以更好地合并更多的专家模型。第五，不同的合并方法在较大规模下表现非常相似。

## 💧新名词：

## 🌏研究背景：

## 🌟重点：

## 🔬实验方法：

## 📜 总结：