# 🔤 Survery：pfl 迈向个性化的联合学习 (2023, Tan) IEEE Trans. Neural Netw. Learning Syst. (8.9 / 2.21 / 1)

**原名：** Towards personalized federated learning

**译名：** 迈向个性化的联合学习

**作者：** Tan et al.

**期刊：** IEEE Transactions on Neural Networks and Learning Systems

**IFQ：** CCF BIF 8.9JCI 2.21SCI Q1

**DOI：** [10.1109/TNNLS.2022.3160699](https://doi.org/10.1109/TNNLS.2022.3160699)

**发表时间：** 12/2023

**本地链接:** [2023-Towards personalized federated learning.pdf](zotero://open-pdf/0_KE8257Y7)


[(99+ 封私信 / 10 条消息) 个性化联邦学习：综述 - 知乎](https://zhuanlan.zhihu.com/p/497934969)

[【阅读笔记】Towards Personalized Federated Learning个性化联邦综述-CSDN博客](https://blog.csdn.net/charlessun9/article/details/125544647)

**摘要：**

摘要—随着人工智能（AI）研究的进步推动人工智能的快速采用，人们对数据隐私的认识和担忧也在日益增长。近期数据监管领域的重要发展促使人们对隐私保护型人工智能的兴趣发生了巨大的转变。这推动了联邦学习（FL）的普及，联邦学习是用于以隐私保护的方式在数据孤岛上训练机器学习模型的主要范例。在本综述中，我们探讨了个性化联邦学习（PFL）领域，以解决联邦学习在异构数据上的根本性挑战，而异构性是所有现实世界数据集的普遍特征。学习，个性化联邦学习，非独立同分布数据，统计异质性，隐私保护，边缘计算。

# 看这一篇笔记：[https://zhuanlan.zhihu.com/p/499716652](https://zhuanlan.zhihu.com/p/499716652)

## **一、个性化联邦学习的两种策略**

- ### **策略一：全局模型个性化，意在提升在异质数据上联邦训练的全局共享模型的性能。**
    

训练好全局FL模型，然后通过本地适应步骤为每个FL客户端进行个性化处理（包括在每个本地数据集上进行额外的训练）。这种两步走的 **"联邦训练+本地适应 "方法（FL training + local adaptation）**是一种重要的联邦个性化策略。由于个性化性能直接取决于全局模型的泛化性能，许多PFL方法旨在先提高全局模型在数据异质性下的性能，以提高随后在本地数据上的个性化性能。

这一类的个性化技术被分为基于数据和基于模型的方法。**基于数据的方法旨在通过减少客户数据集之间的统计异质性来缓解客户漂移问题，而基于模型的方法旨在学习一个强大的全局模型，以便在未来对单个客户进行个性化定制或提高本地模型的适应性。**

- ### **策略二：学习个性化的模型，意在提供个性化解决方案。**
    

与训练单一全局模型的全局模型个性化策略不同，这类的方法在每个客户端上**训练单个的个性化模型**。其目标是通过修改FL模型的聚合过程来建立个性化的模型。这是通过在FL环境中应用不同的学习范式实现的。

**个性化技术被分为基于架构和基于相似性的方法。基于架构的方法旨在为每个客户提供量身定制的个性化模型架构，而基于相似性的方法旨在利用客户关系来提高个性化模型的性能，即为相关客户建立类似的个性化模型。**

## **二、个性化联邦学习的四大类十小类解决方案**

![](https://pic2.zhimg.com/v2-aa0e4e1b0311cad2eedca3c18aed3a4d_1440w.jpg)

这篇论文将个性化联邦学习分为前述两种策略，然后又在策略之下介绍了四大类十小类解决方案。