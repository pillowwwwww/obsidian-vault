# 🔤 联邦学习的泛化性、鲁棒性和公平性：综述与基准测试 (2024, Huang) IEEE Trans. Pattern Anal. Mach. Intell. (18.6 / 4.66 / 1)

**原名：**Federated learning for generalization, robustness, fairness: A survey and benchmark

**译名：** 联邦学习的泛化性、鲁棒性和公平性：综述与基准测试

**作者：**Huang et al.

**期刊：**IEEE Transactions on Pattern Analysis and Machine Intelligence

**IFQ：**CCF AIF 18.6JCI 4.66SCI Q1

**DOI：** [10.1109/TPAMI.2024.3418862](https://doi.org/10.1109/TPAMI.2024.3418862)

**发表时间：**12/2024

**本地链接:** [2024-Federated learning for generalization, robustness, fairness A survey and benchmark.pdf](zotero://open-pdf/0_3Y47EPZV)

PAMI的一篇综述，黄文柯的。

该文章的框架写的不错，框架图可以。

紫红色是待看部分！
最后的总结没看！！

**摘要：**

联邦学习已成为一种很有前景的隐私保护协作范式，用于不同参与方之间的协作。近年来，随着联邦学习的普及，涌现出大量方法来应对各种现实挑战。本综述系统地概述了联邦学习研究的最新重要进展。首先，我们介绍了该领域的学习历史和术语定义。然后，我们全面回顾了三个基本的研究方向：泛化、鲁棒性和公平性，并介绍了它们各自的背景概念、任务设置和主要挑战。我们还对方法和数据集的代表性文献进行了详细概述，并在几个知名数据集上对所回顾的方法进行了基准测试。最后，我们指出了该领域的一些开放性问题，并提出了进一步研究的机会。我们还提供了一个公共网站来持续跟踪这一快速发展领域的进展：https://github.com/WenkeHuang/MarsFL

## 💧新名词：

✅ 什么是经验损失（Empirical Loss）？和 loss 有什么区别？

**Loss**通常指单个样本的损失函数，比如交叉熵、均方误差等。记作  
$L(w; x,y)$。表示模型参数 $w$ 对样本 $(x,y)$ 的即时损失。

经验损失（Empirical Loss）则是将所有本地样本的 Loss 求平均或加权和，用来衡量模型在整个本地数据集上的整体表现。就是我们平常所指的loss.

|名称|符号表达|解释|
|---|---|---|
|**理论期望/真实风险**|$R(w) = \mathbb{E}_{(x,y)\sim P}[L(w;x,y)]$|理论上最想优化的目标，但因未知的真实分布而无法直接计算|
|**经验期望/经验风险**|$\hat{R}(w) = \frac{1}{n} \sum_{i=1}^n L(w;x_i,y_i)$|在训练集上计算的平均损失，是我们用来近似真实风险的可操作目标|

|概念中文|概念英文|数学表达|含义|
|---|---|---|---|
|损失|Loss|$L(w; x, y)$|单个样本的误差度量|
|风险|Risk|$\mathbb{E}[L(w; x,y)]$ 或 $\frac{1}{n} \sum L$|所有样本上的平均损失（期望）|
|期望|Expectation|$\mathbb{E}_{x \sim P}[f(x)]$|从概率角度看平均值（数学运算）|

🔢 什么是 Digits 场景？

“Digits 场景”是指一个常见的实验设置，它将多个 手写数字识别类数据集 视为来自不同客户端的数据源，以模拟跨领域（cross-domain）联邦学习。

手写数据集包括MINIST\SVHN\USPS等。

分布差异：分布差异指（X，y）的分布差异

|类型|解释|
|---|---|
|**特征分布差异** $P_i(x)$|图像风格、清晰度、颜色、尺寸不同（如 MNIST vs SVHN）|
|**标签分布差异** $P_i(y)$|某些客户端可能偏向特定数字，如只包含0–4类（非均匀）|
|**联合分布差异** $P_i(x, y)$|包含上面两种情况，是综合性差异（最常用定义）|

### 🧩 1. 多梯度下降（Multi-Gradient Descent）

#### ✅ 定义

多梯度下降是一种优化策略，用于**同时优化多个目标函数**（multi-objective optimization）。  
在联邦学习中，每个客户端的本地损失可以看作一个单独的目标函数，多个客户端一起训练时，就是一个多目标优化问题。

### 🧩 2. 帕累托最优解（Pareto Optimality）

#### ✅ 定义

帕累托最优解是一种**多目标最优化的判据**，表示**没有任何一个目标能改进而不损害其他目标**。

#### ✅ 在联邦学习中的含义：

你希望所有客户端的损失都尽可能小，但在现实中无法做到**全部最小**。所以：

- 如果当前参数 $w$ 使得 **无法低一个客户端的损失**，除非是**增加另一个客户端的损失**则它是帕累托最优的。

### 🧩 3. 余弦相似度（Cosine Similarity）

#### ✅ 定义

余弦相似度是衡量两个向量夹角的相似程度，而不是大小。常用于衡量**两个梯度方向是否一致**。

公式如下：

$$\cos(\theta) = \frac{A \cdot B}{\|A\| \|B\|} = \frac{\sum_i A_i B_i}{\sqrt{\sum_i A_i^2} \sqrt{\sum_i B_i^2}}$$
- $$ A⋅B$$      表示两个向量的**点积**（也就是逐维相乘后求和）；
- ∣∣A∣∣：是向量 a 的**长度**（L2范数）；
余弦相似度是一个 **衡量两个向量方向是否一致** 的指标：

- 如果两个向量方向完全相同，余弦相似度 = 1；
    
- 如果两个向量方向完全相反，余弦相似度 = -1；
    
- 如果两个向量垂直（无关），余弦相似度 = 0。

#### ✅ 在联邦学习中的作用：

例如在 FedFV 中，使用余弦相似度来：

- 判断客户端上传梯度之间是否存在“冲突”；
- 如果方向矛盾，表示客户端优化目标差异大，就需要调整权重避免“内耗”。

---

## 🌏研究背景：

遇到了三个挑战：

1. Generalization
    
    联邦学习中的数据来自多个不同来源，每个客户端的数据具有不同的偏好和特征，因此天然具有非独立同分布（Non-IID）特性 [33]-[39]，这对模型的泛化能力构成重大挑战。泛化问题主要体现在以下两类分布偏移：
    
    - Cross-Client Shift（跨客户端分布偏移）  
        不同客户端的数据分布差异大，导致每个客户端在本地训练时，会朝向其各自的局部经验最小值进行优化。  
        这使得本地模型的优化方向彼此分离，难以有效融合成统一的全局模型，进而导致：
        
        - 全局模型的收敛速度慢；
        - 模型性能不稳定、效果不理想；
        - 聚合模型难以适配所有客户端。
    - Out-Client Shift（外客户端分布偏移）  
        联邦模型的训练依赖于当前在线的参与客户端数据。当该模型部署到未曾参与训练的外部客户端或全新测试域时，由于训练时从未接触此类分布，导致：
        
        - 模型对新域适应性差；
        - 泛化能力不足，实际预测精度明显下降；
        - 难以应用于开放环境下的泛用性场景，如跨医院、跨城市部署等。  
            
    
    因此，提升联邦学习模型的泛化能力是实现其在现实环境中高效收敛与准确预测的基础要求。
    
2. Robustness
    
    - Byzantine Attack：恶意客户端篡改模型更新，破坏收敛性和性能（包括基于数据和基于模型的拜占庭攻击）[50]-[58]。
    - Backdoor Attack：注入后门触发器，使模型在特定输入下输出攻击者指定标签，同时在正常任务上保持性能[59]-[64]
        
        这些攻击利用联邦学习分布式、隐私保护的特点，更加隐蔽且破坏性强，严重影响系统鲁棒性。
        
3. Fairness
    
    Collaboration Fairness：若没有合理的激励机制与收益分配，客户端缺乏参与意愿[65]-[70]。
    
    Performance Fairness：部分客户端（数据量少或分布偏差大）在全局模型中获益较少，预测效果偏低[71]-[73]。
    

我们认为，**Generalization、Robustness 和 Fairness** 是联邦学习发展的三个核心维度：

- **Generalization**：提升模型在非IID分布下的适应能力；
- **Robustness**：增强系统应对恶意攻击的防御能力；
- **Fairness**：实现多方协作中的合理利益分配与可持续合作。

## 🌟重点：

如何解决联邦学习的利益冲突和公平性？

解决方法：使用博弈论中的 Shapley Value（夏普利值）

> 在一个团队中，每个成员到底“单独多贡献了多少”？

在联邦学习中，我们使用夏普利值来评估每个客户端对最终模型精度的贡献程度，然后据此给它分配奖励。

#### 2.2.2 拜占庭攻击&后门攻击

**主要分为两类：污染数据（Data-Based）和 篡改模型参数（Parameter-Based）**

- 污染数据

| 类型                | 名称           | 翻转方式               | 噪声矩阵特点     |
| ----------------- | ------------ | ------------------ | ---------- |
| Symmetry Flipping | 对称翻转 (SymF)  | 原始标签 → 任意其他类别（等概率） | 非对角线均匀分布   |
| Pair Flipping     | 配对翻转 (PairF) | 原始标签 → 固定“相邻”类别    | 非对角线只有一列有值 |

- 篡改模型参数

#### 2.2.3 利益冲突

|类型|问题|原因|解决方式 / 衡量|
|---|---|---|---|
|**奖励冲突**|不同客户端贡献不等，难以公平分配|数据质量/计算资源不同|使用 **Shapley Value** 衡量边际贡献|
|**预测偏差**|模型在不同客户端预测精度不一致|数据异构（Domain Skew）分布不同|使用 **性能标准差 $\zeta$** 衡量公平性|

### 3. 泛化

在联邦学习中，泛化能力（Generalization）的目标是：

> 让一个在多个客户端上训练出来的模型，在**未见过的分布或测试集**上依然有良好表现。

针对联邦学习中的**数据分布异质性**问题，本文将泛化性问题分为两个方向：

- **Cross-Client Shift（跨客户端偏移）**：客户端间分布不同。
- **Out-Client Shift（客户端外部偏移）**：训练时从未参与的客户端，其数据分布未知。

### 3.1

于是，需要两个指标来衡量训练后的模型能否泛化到这两类分布：

|指标|解释|示例场景举例|用于衡量|
|---|---|---|---|
|$\mathcal{A}^U$|Cross-Client Accuracy|使用了 4 个大医院数据作为训练客户端。测在这几个医院内的新数据上表现如何；|模型在训练客户端之间的泛化能力<br><br>标签偏移或域偏移|
|$\mathcal{A}^O$|Out-Client Accuracy|测部署到未参与训练的一个乡村诊所（未见分布）上表现如何。|模型在未知客户端上的泛化能力（迁移能力）<br><br>新域上的泛化能力。|

### 3.2

#### 3.2.1 Client Regularization 客户端正则化  【代办：每一种选一篇论文研究】

|核心思想|典型方法|优点|缺点|
|---|---|---|---|
|使用全局模型引导本地训练|FedProx, SCAFFOLD, MOON|指导性强|本地计算成本高|
|构建跨客户端的全局 **统计表示**（例如：每个类别的原型向量或分布），用于初始化或正则本地模型。|FedProto, FedFA|粒度细腻|需要大量数据支持|
|通过引入 **额外的辅助网络模块**（如GAN、辅助分支）来建模跨客户端的分布偏差，提升局部模型的一致性。|FedGAN, FedMLB|表达力强|通信和兼容性代价高|
|不依赖共享模型或全局统计信息，通过本地模型 **自我增强、自我引导** 提高泛化能力。|FedRS, FedSAM, FedLC|隐私友好、成本低|对超参数敏感，鲁棒性差|

#### 3.2.2 客户端增强

|方法类别|核心思路|示例方法|关键操作说明|
|---|---|---|---|
|**Federated Data Sharing** （联邦数据共享）|在联邦训练前或过程中，**共享一小部分数据**（有标签或无标签）作为全体训练的公共参考，提高各客户端的初始模型一致性|DC-Adam [164] FEDAUX [165]|使用辅助数据集进行预热训练（warm-up）或蒸馏（distillation）|
|**Federated Data Enhancement** （联邦数据增强）|各客户端通过本地数据增强（如 MixUp、生成模型、归一化扰动等），**模拟更加接近理想分布的训练数据**，减缓客户端分布差异|FedMix [166] FEDGEN [167]|采用混合样本合成、生成模型或批归一化重构等方法增强本地样本多样性|
|**Federated Data Selection** （联邦数据选择）|在不增加新数据的前提下，**动态选择客户端或其本地样本中更具代表性的部分参与训练**，提升收敛效率与全局模型表现|FedACS [169] SafeFL [169]|使用聚类或热度排序方法过滤低质量样本或选择分布接近全局的客户端进行训练|

#### 3.2.3 Server Operation（服务器端操作）

在应对 **Cross-Client Shift（跨客户端偏移）** 时，不仅可以调整客户端的本地优化方向，还可以**在服务器端通过聚合和优化策略改进整体模型收敛与泛化性能**。

① Server Aggregation Reweighting（服务器聚合重加权）

② Server Adaptive Optimization（服务器自适应优化**自身的参数**，更好地适应跨客户端的模型泛化目标）

### **3.3** Unknown Generalization**未知领域泛化**

#### 3.3.1 Federated Domain Adaptation  联邦领域自适应    
FDA 是当前非常热门的研究方向，基本假设是：在训练过程中可以访问**未标注的目标域数据**（target domain unlabeled data）。    
目标是：让联邦模型对“目标域”也有较好的泛化能力。
FDA方法主要包括两类：
	① Federated Domain Alignment（联邦域对齐）

**思路：**  
通过对齐不同域之间的特征分布，让模型学习到跨域通用的表示（domain-invariant representations）。

**常用技术手段：**

|技术名称|简要说明|
|---|---|
|对比学习 (Contrastive Learning)|增强不同域样本间的相似性/差异性表示|
|知识蒸馏 (Knowledge Distillation)|用源域模型引导目标域模型学习特征|
|对抗学习 (Adversarial Learning)|用判别器区分域特征，特征提取器欺骗判别器以达成对齐|
|梯度匹配 (Gradient Matching)|对齐源域与目标域的梯度方向|

- ② Federated Domain Disentanglement（联邦域解耦）

思路：  
把模型特征分为两类：

Domain-Invariant（跨域通用特征）和Domain-Specific（仅对某域有效的特征）

通过模型结构设计，将这两类特征分离开来，从而提升泛化能力。

**代表方法：**

- [46], [50]：将**对抗性自适应技术（Adversarial Adaptation）**扩展到联邦框架中。
- [219]：将域无关特征提取器和多个域特定分类器进行显式解耦。
- [151]：引入 Mixture of Experts（专家混合模型），通过 gating 机制协调域专家和通用专家。

**挑战：**  
这些方法通常需要：

- 额外的神经网络模块（例如多个专家网络）；
- 额外的训练机制（例如 gating 控制）。

> 因此**计算资源和通信开销较大，部署成本高**

通过模型结构设计，将这两类特征分离开来，从而提升泛化能力。

3.3.2 Federated Domain Generalization  
    **联邦领域泛化**
    
- 1. **Federated Invariant Optimization（联邦不变性优化）  
		**目标：修改客户端训练目标，使其**学到对不同域都适用的表征（domain-invariant representation）**，从而减少模型对某些特定域的偏倚。
	1. **Federated Invariant Aggregation（联邦不变性聚合）**
		
		目标：不改训练目标，而是通过优化**服务器端聚合策略**，提高模型对不同域的适应能力。
		

---

## 4 Robust Federated Learning 鲁棒的联邦学习

#### 4.1 Robustness Metrics

**4.1 鲁棒性评估指标**

#### 4.2 Byzantine Attack

**4.2 拜占庭攻击**

- 4.2.1 Data-Based Byzantine Attack  
    **基于数据的拜占庭攻击**
- 4.2.2 Model-Based Byzantine Attack  
    **基于模型的拜占庭攻击**

#### 4.3 Backdoor Attack

**4.3 后门攻击**

---

### **5 Fair Federated Learning**

**公平的联邦学习**

### **5.1 公平性评估指标** Fairness Metrics

### ① **Contribution Match Degree：𝓔（贡献匹配度）**

目的：衡量一个客户端在系统中的真实贡献”是否与它收到的奖励（比如αi）相匹配。

[Go to annotation](zotero://open-pdf/library/items/3Y47EPZV?page=10&annotation=undefined) “The Eq. (18)”：

### ② **Performance Deviation：𝓥（性能偏差）**

目的：衡量模型在不同客户端数据分布上预测准确率的一致性。

- **ν 越大** → 各域之间的性能差距越大，说明模型对某些域表现很好，却对另一些域表现很差 → **偏差（bias）更严重**。
- **ν 越小** → 各域准确率更接近 → **性能更均匀、更公平**。

**5.2**“Collaboration Fairness协作公平

|方法类型中文|核心逻辑（含中文解释）|优点（Advantages）|局限性（Limitations）|
|---|---|---|---|
|个体贡献评估|通过每个客户端自己的数据成本、训练效果或声誉机制等指标来评估其对联邦模型的贡献，无需考虑其他客户端。|实现简单；只需本地信息；可扩展性强|假设客户端诚实；难以处理数据极度异构情况|
|边际贡献评估|衡量每个客户端“是否加入”对整体性能的影响，从而计算其边际贡献，是一种合作博弈中的公平分配思想。|理论最公平；可量化每个客户端的实际影响力|计算复杂度高（O(2^n)）；可能需要辅助验证数据|

**5.3 预测偏差**Prediction Biases

- 性能去偏优化：通过**修改本地损失函数**，让客户端在训练过程中就考虑“公平性约束”。
    
    - 关注单一最差客户端
    - 关注多个客户端
- 性能去偏重加权：不从客户端本地目标入手，而是从**服务器的聚合角度**调节权重，让“受损客户端”在参数聚合中**权重大一点**，提升他们的表现。
    

---

### **6 Experiment Setup实验设置**

6.1 实验数据集（Experimental Datasets）

6.1.1 标签偏移（Label Skew）数据集

- 标签偏移指的是——**客户端本地的类别分布和全局不一致**，例如：
    
    - 有的客户端只拥有一小部分标签（如只含有猫和狗的图片）；
    - 另一些客户端拥有的标签类别更丰富或完全不同。
- #### 📐 生成方式
    
    通过**狄利克雷分布 Dir(β)** 模拟标签不均衡：
    
    - β 越小，本地数据越倾向于某几个类别（也就是更“偏”）；
    - β 越大，表示本地数据更接近全局平均分布。

6.1.2 域偏移与外部分布偏移（Domain Skew & Out-Client Shift）数据集

- **Domain Skew（域偏移）**：各客户端数据来自**不同来源域**，虽然任务一样（如分类数字），但图像风格、数据特征明显不同；
- **Out-Client Shift（外部分布偏移）**：一种更极端的设置。将某一个域完全**排除在训练之外**，仅作为测试使用。

### 6.1.3 Data Augmentation 数据增强

规定了超参数的取值以及数据增强策略

6.2 设置了实验细节，规定超参数的取值，模型结构等等。

table7-9:

**数据异构类型不同**

- Table 7：**标签分布不均**，同一域内特征相近，只是类比例不同。
- Table 8：**特征域差异**，标签空间相同，但图像风格/来源不同（手写→照片→素描）。
- Table 9：**严格留域测试**，模拟完全未见域（Out-Client）对模型泛化的挑战。

训练 vs. 测试划分：

**Table 8**：任务一致（同样的分类任务），但**不同来源域**——所有域都参与训练，测试的是模型在这些**已知域**上的表现。

**Table 9**：同样任务与域划分，但只训练在**部分域**上，把一个域当作真正的“未知”环境，仅在该域上测试，以考察模型的**泛化到完全没见过域**的能力。

---

### **7 Empirical Benchmark Analysis** **实证基准分析**
这段“讨论”中，作者针对整个基准实验和现有文献，总结出了三个不足和未来方向：

1. 可复现性困境（Reproducible Dilemma）

- **现状**：很多新算法在论文中**没有详细给出实验配置**（超参数、训练细节、随机种子等），甚至**不开源代码**。
    
- **后果**：不同论文用的**数据集、模型骨干网络**各不相同，无法做到“同一场景下比精度”，导致**公平对比**、**复现验证**都变得不可能。
    
- **建议**：研究者要在论文里完整披露实验配置、发布代码，并尽量在统一平台/数据集上做对比。

2. 计算开销盲区（Computation Cost）

- **现状**：绝大多数工作只关注“精度指标”，**不报告**它们的**训练时长**、**显存占用**、**通信开销**等关键资源开销。
    
- **问题**：联邦学习在现实中分为“跨设备”（millions of clients, 资源受限）和“跨机构”（few clients, 可用资源多）两种场景，不同设定下**算力/内存**都有严格要求。
    
- **后果**：一些看似“性能大幅提升”的方法，其实可能借助了大规模 GPU 集群或长时间训练，这在**真实部署**中难以接受。
    
- **建议**：未来研究应同时报告**时空复杂度**（训练时间、内存/带宽需求），并开发**轻量级**、**高效**的联邦算法。
    
3. “万金油”范式缺失（Thinking Everything Failure）

- **现状**：现有研究大多**“各自为政”**：
    
    - 有的只解决**数据异构**（Non-IID）；
        
    - 有的只防御**拜占庭/后门攻击**；
        
    - 有的只关注**公平性**；
        
    - 很少有方法能在这三大挑战（Generalization/Robustness/Fairness）之间兼顾。
        
- **后果**：一个方法在数据异构场景下表现好，可能在攻击场景下失效；一个方法能防攻击，却牺牲了精度或公平。
    
- **建议**：未来要思考能否提出一个**统一的联邦学习框架**，能够同时：
    
    1. 适应多种数据分布；
        
    2. 抵抗各种恶意行为；
        
    3. 保证各方利益分配与性能均衡。
---

### **8 Open Questions and Future Directions**

**开放问题与未来方向**

第 8.1 节其实是在把前三章的观察和基准实验结果，提炼成未来要重点突破的几大「悖论」和研究方向。下面我逐条拆开来、结合前面看到的实验证据，帮你完整地理清每一点的来龙去脉和潜在出路。

---

### 1. Generalization & Robustness Dilemma

- **问题**：
    
    - **泛化**要让模型学到来自所有客户端的多样性知识；
        
    - **鲁棒**要把恶意客户端（拜占庭、后门）识别剔除出去。
        
- **矛盾点**：
    
    - 当某些客户端本地数据分布非常与众不同时（极端 Label Skew/Domain Skew），它们的更新往往偏离大多数客户端的「主流方向」，
        
    - 鲁棒机制（如距离或统计方法）可能误把这些**良性但“异类”**更新当成恶意，把它们剔掉→**损失了珍贵的少数分布信息**→反过来又削弱了全局模型对这部分类别/域的泛化能力。
        
- **潜在方向**：
    
    1. **联合判别**：不只看更新的“偏离程度”，还要结合**模型不确定度**、**历史贡献**等多信号；
        
    2. **软排除机制**：给这类“异常但可能有价值”的客户端一个小权重，而不是完全剔除；
        
    3. **自适应阈值**：根据当前全局性能动态调整“什么程度才算恶意”——分布越多样、容忍度也越高。
        

---

### 2. Generalization & Fairness Trade-Off

- **问题**：
    
    - **泛化**追求“平均精度” AUA^UAU 尽可能高；
        
    - **性能公平**（ν）追求“各客户端/域精度波动”尽可能小。
        
- **矛盾点**：
    
    1. **速度 vs 少数**：最快收敛通常要往“数据量大、样本丰富”的主流客户端分布靠拢，而少数分布就会被忽略，导致 ν 较大；
        
    2. **均值 vs 方差**：“最小均方差”往往会牺牲整体平均精度，特别是在极端非 IID 下。
        
- **潜在方向**：
    
    1. **多目标优化**：设计同时优化 max⁡AU\max A^UmaxAU 和 min⁡ν\min \numinν 的损失，借鉴多目标或公平学习（Fair ML）里的帕累托前沿方法；
        
    2. **动态权衡**：在训练早期以平均精度为主（加速收敛），后期逐步转向均衡精度；
        
    3. **纠偏正则**：在 FedAvg/FedProx 这类基础上加一个“少数域惩罚”项，使少数精度低时主动拉高。
        

---

### 3. Robustness & Fairness Cooperation

- **相辅相成**：
    
    - **公平的合作机制**（高 E）要求**准确评估**每个客户端的边际贡献，恰恰就是在数据质量和更新“价值”上做判断——这能帮助我们区分“真的没贡献”与“恶意投毒”，从而**辅助鲁棒**；
        
    - **可靠的鲁棒机制**（只留下良性客户端）则能**保障**公平机制的前提：只有可信参与者，奖励分配才有意义。
        
- **潜在方向**：
    
    1. **统一度量**：用同一套“贡献+不确定度”评分，既当作鲁棒判别，也当作公平奖励；
        
    2. **闭环设计**：在每轮聚合后，用公平指标剔除表现极差（或贡献极低）的更新，同时在鲁棒筛选中保留那些对公平有大正面贡献的客户端；
        
    3. **博弈论视角**：把客户端当作“理性博弈者”，设计既防御攻击又保证长期合作激励机制。
        

---

### 4. Vertical FL 遇上 GRF

- **Vertical FL（VFL）特点**：多方拥有**同一批实体**的不同特征片段，要**对齐特征、拼接表征**，再做联合训练。
    
- **新挑战**：
    
    1. **特征对齐 & 缺失**：有方可能少某些特征（数据缺失），如何在不引入偏差的情况下把不同片段拼接成统一表征？
        
    2. **推断攻击**：对齐过程中可能通过梯度或中间激活泄漏标签/特征→需要更强的加密/安全聚合协议；
        
    3. **贡献不平衡**：有些特征维度对最终预测作用巨大，如何在 VFL 中衡量“谁贡献大”，并公平分配收益？
        
- **潜在方向**：
    
    1. **异构对齐网络**：设计无监督对齐层(PCA、变分AE、对抗align)，在保隐私前提下最小化拼接误差；
        
    2. **Secure MPC/HE**：在 VFL 上应用安全多方计算或同态加密，保证中间交换的梯度/加权过程不泄密；
        
    3. **跨维度公平**：既要公平看“方”贡献，也要公平看“特征组”贡献，为特征维度划分一套 Shapley-style 评分。
        

---

### 5. Federated LLM

- **挑战**：
    
    1. **模型超大**（数百亿参数）→ **通信开销**成天文数字；
        
    2. **知识产权保护**→ 不能随意把全量参数或下游样本泄露给第三方；
        
    3. **数据隐私 vs 通用性**：LLM 要吃海量多样化数据，隐私敏感域（医疗、金融）数据更不能弃用。
        
- **潜在方向**：
    
    1. **蒸馏 + 索引通信**：只交换关键子网/梯度子集，或用低秩分解、剪枝、量化后通信；
        
    2. **参数加密 & 区块链**：用安全聚合 + 联邦式区块链来确保交易不可篡改、可审计；
        
    3. **联邦微调**：在 LLM 顶层做小批量 adapter 微调，把大模型主体留在云端，只联邦共享 adapter 权重。
        

---

## 总结

- **三个「囚徒困境」**（Gen↔Rob，Gen↔Fair，Rob↔Fair）指出了当前方法的单维度优化瓶颈；
    
- **VFL** 和 **LLM** 是两大前沿应用场景，分别在**特征对齐安全**和**超大模型通信/隐私**层面提出新难题；
    
- **未来研究**需要在**算法设计、系统架构、协议安全**三条腿一起发力，才能让联邦学习在现实中既**高效**、又**安全**、又**公平**。

## 🔬实验方法：

## 📜 总结：